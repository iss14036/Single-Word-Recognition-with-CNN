{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D,AveragePooling2D,ZeroPadding2D,BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/daniel/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "DATA_PATH = \"/home/daniel/data/\"\n",
    "\n",
    "# Input: Folder Path\n",
    "# Output: Tuple (Label, Indices of the labels, one-hot encoded labels)\n",
    "def get_labels(path=DATA_PATH):\n",
    "    labels = os.listdir(path)\n",
    "    label_indices = np.arange(0, len(labels))\n",
    "    return labels, label_indices, to_categorical(label_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['marvin',\n",
       " 'happy',\n",
       " 'six',\n",
       " 'up',\n",
       " 'stop',\n",
       " 'yes',\n",
       " 'sheila',\n",
       " 'zero',\n",
       " 'dog',\n",
       " 'right',\n",
       " 'house',\n",
       " 'no',\n",
       " 'two',\n",
       " 'left',\n",
       " 'cat',\n",
       " 'nine',\n",
       " 'seven',\n",
       " 'three',\n",
       " 'wow',\n",
       " 'bed']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, _, _ = get_labels(DATA_PATH)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Handy function to convert wav2mfcc\n",
    "def wav2mfcc(file_path, max_len=11):\n",
    "    wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
    "    wave = wave[::3] #downsampling, \n",
    "    mfcc = librosa.feature.mfcc(wave,sr=22050, n_mfcc=13)\n",
    "\n",
    "    # If maximum length exceeds mfcc lengths then pad the remaining ones\n",
    "    if (max_len > mfcc.shape[1]):\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "    # Else cutoff the remaining parts\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "    \n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_data_to_array(path=DATA_PATH, max_len=11):\n",
    "    labels, _, _ = get_labels(path)\n",
    "\n",
    "    for label in labels:\n",
    "        # Init mfcc vectors\n",
    "        mfcc_vectors = []\n",
    "\n",
    "        wavfiles = [path + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
    "        for wavfile in wavfiles:\n",
    "            mfcc = wav2mfcc(wavfile, max_len=max_len)\n",
    "            mfcc_vectors.append(mfcc)\n",
    "        np.save(label + '.npy', mfcc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_test(split_ratio=0.8, random_state=42):\n",
    "    # Get available labels\n",
    "    labels, indices, _ = get_labels(DATA_PATH)\n",
    "\n",
    "    # Getting first arrays\n",
    "    X = np.load(labels[0] + '.npy')\n",
    "    y = np.zeros(X.shape[0])\n",
    "\n",
    "    # Append all of the dataset into one single array, same goes for y\n",
    "    for i, label in enumerate(labels[1:]):\n",
    "        x = np.load(label + '.npy')\n",
    "        X = np.vstack((X, x))\n",
    "        y = np.append(y, np.full(x.shape[0], fill_value= (i + 1)))\n",
    "\n",
    "    assert X.shape[0] == len(y)\n",
    "\n",
    "    return train_test_split(X, y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from preprocess import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Second dimension of the feature is dim2\n",
    "feature_dim_2 = 11\n",
    "\n",
    "# Save data to array file first\n",
    "save_data_to_array(max_len=feature_dim_2)\n",
    "\n",
    "# # Loading train set and test set\n",
    "X_train, X_test, y_train, y_test = get_train_test()\n",
    "\n",
    "# # Feature dimension\n",
    "feature_dim_1 = 13\n",
    "channel = 1\n",
    "epochs = 25\n",
    "batch_size = 100\n",
    "verbose = 1\n",
    "num_classes = 20\n",
    "\n",
    "# Reshaping to perform 2D convolution\n",
    "X_train = X_train.reshape(X_train.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "X_test = X_test.reshape(X_test.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicts one sample\n",
    "def predict(filepath, model):\n",
    "    sample = wav2mfcc(filepath)\n",
    "    sample_reshaped = sample.reshape(1, feature_dim_1, feature_dim_2, channel)\n",
    "    return get_labels()[0][\n",
    "            np.argmax(model.predict(sample_reshaped))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_lenet():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(20, kernel_size=(5, 5), strides=1, input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n",
    "    model.add(ZeroPadding2D(padding=(2,2)))\n",
    "    model.add(Conv2D(50, kernel_size=(5, 5),strides=1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27200 samples, validate on 6800 samples\n",
      "Epoch 1/25\n",
      "27200/27200 [==============================] - 7s 272us/step - loss: 1.9861 - acc: 0.4376 - val_loss: 1.3001 - val_acc: 0.5954\n",
      "Epoch 2/25\n",
      "27200/27200 [==============================] - 6s 205us/step - loss: 0.9913 - acc: 0.6940 - val_loss: 0.8310 - val_acc: 0.7413\n",
      "Epoch 3/25\n",
      "27200/27200 [==============================] - 6s 206us/step - loss: 0.7494 - acc: 0.7654 - val_loss: 0.8805 - val_acc: 0.7375\n",
      "Epoch 4/25\n",
      "27200/27200 [==============================] - 6s 206us/step - loss: 0.6201 - acc: 0.8032 - val_loss: 0.7565 - val_acc: 0.7663\n",
      "Epoch 5/25\n",
      "27200/27200 [==============================] - 6s 214us/step - loss: 0.5348 - acc: 0.8274 - val_loss: 0.6994 - val_acc: 0.7876\n",
      "Epoch 6/25\n",
      "27200/27200 [==============================] - 6s 206us/step - loss: 0.4481 - acc: 0.8551 - val_loss: 0.6644 - val_acc: 0.8001\n",
      "Epoch 7/25\n",
      "27200/27200 [==============================] - 6s 210us/step - loss: 0.3976 - acc: 0.8701 - val_loss: 0.6647 - val_acc: 0.8044\n",
      "Epoch 8/25\n",
      "27200/27200 [==============================] - 7s 250us/step - loss: 0.3390 - acc: 0.8884 - val_loss: 0.7071 - val_acc: 0.8060\n",
      "Epoch 9/25\n",
      "27200/27200 [==============================] - 7s 250us/step - loss: 0.2868 - acc: 0.9062 - val_loss: 0.7080 - val_acc: 0.8125\n",
      "Epoch 10/25\n",
      "27200/27200 [==============================] - 7s 263us/step - loss: 0.2539 - acc: 0.9156 - val_loss: 0.7562 - val_acc: 0.8046\n",
      "Epoch 11/25\n",
      "27200/27200 [==============================] - 8s 294us/step - loss: 0.2243 - acc: 0.9258 - val_loss: 0.7856 - val_acc: 0.8084\n",
      "Epoch 12/25\n",
      "27200/27200 [==============================] - 7s 268us/step - loss: 0.1833 - acc: 0.9404 - val_loss: 0.8145 - val_acc: 0.8053\n",
      "Epoch 13/25\n",
      "27200/27200 [==============================] - 7s 254us/step - loss: 0.1679 - acc: 0.9425 - val_loss: 0.8432 - val_acc: 0.8054\n",
      "Epoch 14/25\n",
      "27200/27200 [==============================] - 7s 254us/step - loss: 0.1370 - acc: 0.9540 - val_loss: 0.9689 - val_acc: 0.7954\n",
      "Epoch 15/25\n",
      "27200/27200 [==============================] - 7s 264us/step - loss: 0.1233 - acc: 0.9586 - val_loss: 0.9859 - val_acc: 0.7904\n",
      "Epoch 16/25\n",
      "27200/27200 [==============================] - 7s 251us/step - loss: 0.1148 - acc: 0.9606 - val_loss: 0.9432 - val_acc: 0.8057\n",
      "Epoch 17/25\n",
      "27200/27200 [==============================] - 7s 264us/step - loss: 0.0993 - acc: 0.9673 - val_loss: 0.9521 - val_acc: 0.8122\n",
      "Epoch 18/25\n",
      "27200/27200 [==============================] - 7s 274us/step - loss: 0.0806 - acc: 0.9735 - val_loss: 1.0282 - val_acc: 0.8099\n",
      "Epoch 19/25\n",
      "27200/27200 [==============================] - 6s 215us/step - loss: 0.0796 - acc: 0.9735 - val_loss: 1.0374 - val_acc: 0.8146\n",
      "Epoch 20/25\n",
      "27200/27200 [==============================] - 6s 238us/step - loss: 0.0651 - acc: 0.9785 - val_loss: 1.1062 - val_acc: 0.8082\n",
      "Epoch 21/25\n",
      "27200/27200 [==============================] - 6s 227us/step - loss: 0.0646 - acc: 0.9774 - val_loss: 1.1728 - val_acc: 0.8040\n",
      "Epoch 22/25\n",
      "27200/27200 [==============================] - 8s 277us/step - loss: 0.0607 - acc: 0.9799 - val_loss: 1.1470 - val_acc: 0.8116\n",
      "Epoch 23/25\n",
      "27200/27200 [==============================] - 6s 218us/step - loss: 0.0547 - acc: 0.9822 - val_loss: 1.1749 - val_acc: 0.8088\n",
      "Epoch 24/25\n",
      "27200/27200 [==============================] - 7s 259us/step - loss: 0.0500 - acc: 0.9830 - val_loss: 1.1405 - val_acc: 0.8169\n",
      "Epoch 25/25\n",
      "27200/27200 [==============================] - 8s 285us/step - loss: 0.0463 - acc: 0.9851 - val_loss: 1.1938 - val_acc: 0.8112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4694b64e50>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model13 = model_lenet()\n",
    "model13.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27200 samples, validate on 6800 samples\n",
      "Epoch 1/25\n",
      "27200/27200 [==============================] - 10s 368us/step - loss: 2.0468 - acc: 0.4487 - val_loss: 1.1870 - val_acc: 0.6278\n",
      "Epoch 2/25\n",
      "27200/27200 [==============================] - 11s 402us/step - loss: 0.9348 - acc: 0.7082 - val_loss: 0.8814 - val_acc: 0.7278\n",
      "Epoch 3/25\n",
      "27200/27200 [==============================] - 10s 372us/step - loss: 0.6756 - acc: 0.7894 - val_loss: 0.8135 - val_acc: 0.7456\n",
      "Epoch 4/25\n",
      "27200/27200 [==============================] - 9s 349us/step - loss: 0.5379 - acc: 0.8292 - val_loss: 0.7048 - val_acc: 0.7853\n",
      "Epoch 5/25\n",
      "27200/27200 [==============================] - 11s 405us/step - loss: 0.4224 - acc: 0.8644 - val_loss: 0.7126 - val_acc: 0.7941\n",
      "Epoch 6/25\n",
      "27200/27200 [==============================] - 9s 349us/step - loss: 0.3351 - acc: 0.8918 - val_loss: 0.7389 - val_acc: 0.7899\n",
      "Epoch 7/25\n",
      "27200/27200 [==============================] - 11s 398us/step - loss: 0.2679 - acc: 0.9117 - val_loss: 0.7141 - val_acc: 0.8066\n",
      "Epoch 8/25\n",
      "27200/27200 [==============================] - 10s 362us/step - loss: 0.2091 - acc: 0.9296 - val_loss: 0.7460 - val_acc: 0.8062\n",
      "Epoch 9/25\n",
      "27200/27200 [==============================] - 10s 372us/step - loss: 0.1717 - acc: 0.9421 - val_loss: 0.8491 - val_acc: 0.8009\n",
      "Epoch 10/25\n",
      "27200/27200 [==============================] - 11s 390us/step - loss: 0.1381 - acc: 0.9549 - val_loss: 0.9051 - val_acc: 0.7987\n",
      "Epoch 11/25\n",
      "27200/27200 [==============================] - 10s 374us/step - loss: 0.1131 - acc: 0.9646 - val_loss: 0.9074 - val_acc: 0.8037\n",
      "Epoch 12/25\n",
      "27200/27200 [==============================] - 11s 390us/step - loss: 0.0966 - acc: 0.9688 - val_loss: 0.9788 - val_acc: 0.8041\n",
      "Epoch 13/25\n",
      "27200/27200 [==============================] - 12s 443us/step - loss: 0.0844 - acc: 0.9718 - val_loss: 1.0110 - val_acc: 0.8018\n",
      "Epoch 14/25\n",
      "27200/27200 [==============================] - 11s 399us/step - loss: 0.0671 - acc: 0.9773 - val_loss: 0.9707 - val_acc: 0.8200\n",
      "Epoch 15/25\n",
      "27200/27200 [==============================] - 10s 377us/step - loss: 0.0632 - acc: 0.9792 - val_loss: 0.9871 - val_acc: 0.8190\n",
      "Epoch 16/25\n",
      "27200/27200 [==============================] - 12s 458us/step - loss: 0.0568 - acc: 0.9808 - val_loss: 1.0990 - val_acc: 0.8034\n",
      "Epoch 17/25\n",
      "27200/27200 [==============================] - 10s 374us/step - loss: 0.0438 - acc: 0.9856 - val_loss: 1.0836 - val_acc: 0.8154\n",
      "Epoch 18/25\n",
      "27200/27200 [==============================] - 11s 401us/step - loss: 0.0470 - acc: 0.9846 - val_loss: 1.0772 - val_acc: 0.8153\n",
      "Epoch 19/25\n",
      "27200/27200 [==============================] - 11s 388us/step - loss: 0.0373 - acc: 0.9882 - val_loss: 1.1458 - val_acc: 0.8132\n",
      "Epoch 20/25\n",
      "27200/27200 [==============================] - 11s 407us/step - loss: 0.0363 - acc: 0.9885 - val_loss: 1.1255 - val_acc: 0.8162\n",
      "Epoch 21/25\n",
      "27200/27200 [==============================] - 10s 377us/step - loss: 0.0408 - acc: 0.9870 - val_loss: 1.1842 - val_acc: 0.8178\n",
      "Epoch 22/25\n",
      "27200/27200 [==============================] - 10s 370us/step - loss: 0.0374 - acc: 0.9885 - val_loss: 1.2332 - val_acc: 0.8088\n",
      "Epoch 23/25\n",
      "27200/27200 [==============================] - 11s 400us/step - loss: 0.0365 - acc: 0.9882 - val_loss: 1.2235 - val_acc: 0.8134\n",
      "Epoch 24/25\n",
      "27200/27200 [==============================] - 11s 403us/step - loss: 0.0255 - acc: 0.9914 - val_loss: 1.2512 - val_acc: 0.8169\n",
      "Epoch 25/25\n",
      "27200/27200 [==============================] - 11s 406us/step - loss: 0.0360 - acc: 0.9882 - val_loss: 1.2281 - val_acc: 0.8176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4691a67d90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model20 = model_lenet()\n",
    "model20.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27200 samples, validate on 6800 samples\n",
      "Epoch 1/25\n",
      "27200/27200 [==============================] - 13s 471us/step - loss: 1.9728 - acc: 0.4579 - val_loss: 1.0695 - val_acc: 0.6721\n",
      "Epoch 2/25\n",
      "27200/27200 [==============================] - 11s 407us/step - loss: 0.9207 - acc: 0.7135 - val_loss: 0.8592 - val_acc: 0.7334\n",
      "Epoch 3/25\n",
      "27200/27200 [==============================] - 12s 456us/step - loss: 0.6632 - acc: 0.7915 - val_loss: 0.7704 - val_acc: 0.7669\n",
      "Epoch 4/25\n",
      "27200/27200 [==============================] - 11s 418us/step - loss: 0.5013 - acc: 0.8402 - val_loss: 0.7064 - val_acc: 0.7885\n",
      "Epoch 5/25\n",
      "27200/27200 [==============================] - 13s 470us/step - loss: 0.4000 - acc: 0.8712 - val_loss: 0.7020 - val_acc: 0.7960\n",
      "Epoch 6/25\n",
      "27200/27200 [==============================] - 16s 571us/step - loss: 0.3048 - acc: 0.8988 - val_loss: 0.6922 - val_acc: 0.8060\n",
      "Epoch 7/25\n",
      "27200/27200 [==============================] - 13s 469us/step - loss: 0.2439 - acc: 0.9195 - val_loss: 0.7457 - val_acc: 0.8034\n",
      "Epoch 8/25\n",
      "27200/27200 [==============================] - 12s 459us/step - loss: 0.1830 - acc: 0.9398 - val_loss: 0.7415 - val_acc: 0.8143\n",
      "Epoch 9/25\n",
      "27200/27200 [==============================] - 15s 554us/step - loss: 0.1439 - acc: 0.9533 - val_loss: 0.8226 - val_acc: 0.8119\n",
      "Epoch 10/25\n",
      "27200/27200 [==============================] - 15s 562us/step - loss: 0.1136 - acc: 0.9612 - val_loss: 0.8703 - val_acc: 0.8074\n",
      "Epoch 11/25\n",
      "27200/27200 [==============================] - 15s 550us/step - loss: 0.0985 - acc: 0.9670 - val_loss: 0.9024 - val_acc: 0.8182\n",
      "Epoch 12/25\n",
      "27200/27200 [==============================] - 14s 514us/step - loss: 0.0772 - acc: 0.9743 - val_loss: 0.9333 - val_acc: 0.8199\n",
      "Epoch 13/25\n",
      "27200/27200 [==============================] - 16s 575us/step - loss: 0.0632 - acc: 0.9788 - val_loss: 0.9877 - val_acc: 0.8074\n",
      "Epoch 14/25\n",
      "27200/27200 [==============================] - 13s 487us/step - loss: 0.0596 - acc: 0.9805 - val_loss: 1.0739 - val_acc: 0.8082\n",
      "Epoch 15/25\n",
      "27200/27200 [==============================] - 18s 664us/step - loss: 0.0524 - acc: 0.9831 - val_loss: 1.1534 - val_acc: 0.8051\n",
      "Epoch 16/25\n",
      "27200/27200 [==============================] - 14s 518us/step - loss: 0.0515 - acc: 0.9827 - val_loss: 1.1025 - val_acc: 0.8212\n",
      "Epoch 17/25\n",
      "27200/27200 [==============================] - 12s 456us/step - loss: 0.0368 - acc: 0.9881 - val_loss: 1.1257 - val_acc: 0.8216\n",
      "Epoch 18/25\n",
      "27200/27200 [==============================] - 12s 434us/step - loss: 0.0459 - acc: 0.9850 - val_loss: 1.1845 - val_acc: 0.8200\n",
      "Epoch 19/25\n",
      "27200/27200 [==============================] - 12s 458us/step - loss: 0.0438 - acc: 0.9867 - val_loss: 1.2231 - val_acc: 0.8137\n",
      "Epoch 20/25\n",
      "27200/27200 [==============================] - 14s 525us/step - loss: 0.0369 - acc: 0.9881 - val_loss: 1.2509 - val_acc: 0.8129\n",
      "Epoch 21/25\n",
      "27200/27200 [==============================] - 14s 517us/step - loss: 0.0328 - acc: 0.9891 - val_loss: 1.1956 - val_acc: 0.8251\n",
      "Epoch 22/25\n",
      "27200/27200 [==============================] - 12s 454us/step - loss: 0.0258 - acc: 0.9921 - val_loss: 1.1791 - val_acc: 0.8282\n",
      "Epoch 23/25\n",
      "27200/27200 [==============================] - 12s 442us/step - loss: 0.0271 - acc: 0.9912 - val_loss: 1.1987 - val_acc: 0.8244\n",
      "Epoch 24/25\n",
      "27200/27200 [==============================] - 12s 449us/step - loss: 0.0211 - acc: 0.9933 - val_loss: 1.3879 - val_acc: 0.8156\n",
      "Epoch 25/25\n",
      "27200/27200 [==============================] - 12s 438us/step - loss: 0.0312 - acc: 0.9896 - val_loss: 1.2554 - val_acc: 0.8219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f46ccefbf50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model26 = model_lenet()\n",
    "model26.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_spnet():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(20, kernel_size=(5, 5),strides=1, input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(ZeroPadding2D(padding=(2,2)))\n",
    "    model.add(Conv2D(50, kernel_size=(5, 5)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(ZeroPadding2D(padding=(2,2)))\n",
    "    model.add(ZeroPadding2D(padding=(2,2)))\n",
    "    model.add(Conv2D(50, kernel_size=(5, 5), strides=1))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27200 samples, validate on 6800 samples\n",
      "Epoch 1/25\n",
      "27200/27200 [==============================] - 8s 302us/step - loss: 2.3699 - acc: 0.2648 - val_loss: 1.7557 - val_acc: 0.4374\n",
      "Epoch 2/25\n",
      "27200/27200 [==============================] - 8s 276us/step - loss: 1.4130 - acc: 0.5552 - val_loss: 1.0622 - val_acc: 0.6635\n",
      "Epoch 3/25\n",
      "27200/27200 [==============================] - 8s 303us/step - loss: 1.0465 - acc: 0.6698 - val_loss: 0.9336 - val_acc: 0.7063\n",
      "Epoch 4/25\n",
      "27200/27200 [==============================] - 8s 308us/step - loss: 0.8750 - acc: 0.7221 - val_loss: 0.8925 - val_acc: 0.7229\n",
      "Epoch 5/25\n",
      "27200/27200 [==============================] - 8s 277us/step - loss: 0.7709 - acc: 0.7553 - val_loss: 0.8223 - val_acc: 0.7490\n",
      "Epoch 6/25\n",
      "27200/27200 [==============================] - 8s 285us/step - loss: 0.7078 - acc: 0.7755 - val_loss: 0.8271 - val_acc: 0.7399\n",
      "Epoch 7/25\n",
      "27200/27200 [==============================] - 8s 285us/step - loss: 0.6587 - acc: 0.7907 - val_loss: 0.7343 - val_acc: 0.7688\n",
      "Epoch 8/25\n",
      "27200/27200 [==============================] - 7s 271us/step - loss: 0.6160 - acc: 0.8056 - val_loss: 0.6626 - val_acc: 0.7969\n",
      "Epoch 9/25\n",
      "27200/27200 [==============================] - 7s 263us/step - loss: 0.5722 - acc: 0.8172 - val_loss: 0.7833 - val_acc: 0.7709\n",
      "Epoch 10/25\n",
      "27200/27200 [==============================] - 7s 270us/step - loss: 0.5405 - acc: 0.8269 - val_loss: 0.7405 - val_acc: 0.7834\n",
      "Epoch 11/25\n",
      "27200/27200 [==============================] - 7s 269us/step - loss: 0.5248 - acc: 0.8291 - val_loss: 0.6833 - val_acc: 0.7944\n",
      "Epoch 12/25\n",
      "27200/27200 [==============================] - 7s 271us/step - loss: 0.4830 - acc: 0.8446 - val_loss: 0.7147 - val_acc: 0.7938\n",
      "Epoch 13/25\n",
      "27200/27200 [==============================] - 8s 276us/step - loss: 0.4728 - acc: 0.8469 - val_loss: 0.7295 - val_acc: 0.7943\n",
      "Epoch 14/25\n",
      "27200/27200 [==============================] - 7s 275us/step - loss: 0.4451 - acc: 0.8552 - val_loss: 0.6275 - val_acc: 0.8113\n",
      "Epoch 15/25\n",
      "27200/27200 [==============================] - 7s 272us/step - loss: 0.4319 - acc: 0.8600 - val_loss: 0.6182 - val_acc: 0.8224\n",
      "Epoch 16/25\n",
      "27200/27200 [==============================] - 7s 271us/step - loss: 0.4133 - acc: 0.8654 - val_loss: 0.6731 - val_acc: 0.8097\n",
      "Epoch 17/25\n",
      "27200/27200 [==============================] - 7s 275us/step - loss: 0.3931 - acc: 0.8718 - val_loss: 0.6543 - val_acc: 0.8112\n",
      "Epoch 18/25\n",
      "27200/27200 [==============================] - 8s 300us/step - loss: 0.3829 - acc: 0.8740 - val_loss: 0.6983 - val_acc: 0.8018\n",
      "Epoch 19/25\n",
      "27200/27200 [==============================] - 10s 361us/step - loss: 0.3607 - acc: 0.8800 - val_loss: 0.7203 - val_acc: 0.8038\n",
      "Epoch 20/25\n",
      "27200/27200 [==============================] - 8s 301us/step - loss: 0.3511 - acc: 0.8843 - val_loss: 0.6821 - val_acc: 0.8087\n",
      "Epoch 21/25\n",
      "27200/27200 [==============================] - 10s 371us/step - loss: 0.3392 - acc: 0.8886 - val_loss: 0.6773 - val_acc: 0.8126\n",
      "Epoch 22/25\n",
      "27200/27200 [==============================] - 11s 398us/step - loss: 0.3247 - acc: 0.8923 - val_loss: 0.7242 - val_acc: 0.8101\n",
      "Epoch 23/25\n",
      "27200/27200 [==============================] - 9s 344us/step - loss: 0.3029 - acc: 0.8994 - val_loss: 0.7077 - val_acc: 0.8179\n",
      "Epoch 24/25\n",
      "27200/27200 [==============================] - 8s 278us/step - loss: 0.2995 - acc: 0.9010 - val_loss: 0.7482 - val_acc: 0.8129\n",
      "Epoch 25/25\n",
      "27200/27200 [==============================] - 11s 407us/step - loss: 0.2861 - acc: 0.9051 - val_loss: 0.7045 - val_acc: 0.8300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feba45a6d90>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model13 = model_spnet()\n",
    "model13.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27200 samples, validate on 6800 samples\n",
      "Epoch 1/25\n",
      "27200/27200 [==============================] - 13s 479us/step - loss: 2.3088 - acc: 0.2845 - val_loss: 1.7398 - val_acc: 0.4566\n",
      "Epoch 2/25\n",
      "27200/27200 [==============================] - 11s 397us/step - loss: 1.3063 - acc: 0.5868 - val_loss: 1.0399 - val_acc: 0.6699\n",
      "Epoch 3/25\n",
      "27200/27200 [==============================] - 12s 439us/step - loss: 0.9376 - acc: 0.7050 - val_loss: 0.9619 - val_acc: 0.7075\n",
      "Epoch 4/25\n",
      "27200/27200 [==============================] - 11s 408us/step - loss: 0.7853 - acc: 0.7552 - val_loss: 0.8058 - val_acc: 0.7497\n",
      "Epoch 5/25\n",
      "27200/27200 [==============================] - 12s 438us/step - loss: 0.6782 - acc: 0.7864 - val_loss: 0.7893 - val_acc: 0.7581\n",
      "Epoch 6/25\n",
      "27200/27200 [==============================] - 12s 440us/step - loss: 0.6178 - acc: 0.8036 - val_loss: 0.8834 - val_acc: 0.7369\n",
      "Epoch 7/25\n",
      "27200/27200 [==============================] - 11s 407us/step - loss: 0.5590 - acc: 0.8206 - val_loss: 0.6835 - val_acc: 0.7919\n",
      "Epoch 8/25\n",
      "27200/27200 [==============================] - 11s 395us/step - loss: 0.5101 - acc: 0.8369 - val_loss: 0.8047 - val_acc: 0.7751\n",
      "Epoch 9/25\n",
      "27200/27200 [==============================] - 11s 395us/step - loss: 0.4720 - acc: 0.8468 - val_loss: 0.6514 - val_acc: 0.8074\n",
      "Epoch 10/25\n",
      "27200/27200 [==============================] - 11s 387us/step - loss: 0.4381 - acc: 0.8581 - val_loss: 0.6457 - val_acc: 0.8119\n",
      "Epoch 11/25\n",
      "27200/27200 [==============================] - 11s 420us/step - loss: 0.4004 - acc: 0.8703 - val_loss: 0.7242 - val_acc: 0.7971\n",
      "Epoch 12/25\n",
      "27200/27200 [==============================] - 12s 451us/step - loss: 0.3717 - acc: 0.8786 - val_loss: 0.7055 - val_acc: 0.8128\n",
      "Epoch 13/25\n",
      "27200/27200 [==============================] - 11s 422us/step - loss: 0.3520 - acc: 0.8853 - val_loss: 0.6893 - val_acc: 0.8091\n",
      "Epoch 14/25\n",
      "27200/27200 [==============================] - 11s 417us/step - loss: 0.3207 - acc: 0.8940 - val_loss: 0.7254 - val_acc: 0.8109\n",
      "Epoch 15/25\n",
      "27200/27200 [==============================] - 11s 421us/step - loss: 0.3072 - acc: 0.8993 - val_loss: 0.8384 - val_acc: 0.7921\n",
      "Epoch 16/25\n",
      "27200/27200 [==============================] - 12s 459us/step - loss: 0.2783 - acc: 0.9078 - val_loss: 0.7430 - val_acc: 0.8179\n",
      "Epoch 17/25\n",
      "27200/27200 [==============================] - 14s 515us/step - loss: 0.2682 - acc: 0.9102 - val_loss: 0.7607 - val_acc: 0.8149\n",
      "Epoch 18/25\n",
      "27200/27200 [==============================] - 12s 427us/step - loss: 0.2416 - acc: 0.9200 - val_loss: 0.7842 - val_acc: 0.8093\n",
      "Epoch 19/25\n",
      "27200/27200 [==============================] - 16s 590us/step - loss: 0.2310 - acc: 0.9238 - val_loss: 0.7771 - val_acc: 0.8190\n",
      "Epoch 20/25\n",
      "27200/27200 [==============================] - 15s 564us/step - loss: 0.2149 - acc: 0.9284 - val_loss: 1.0714 - val_acc: 0.7760\n",
      "Epoch 21/25\n",
      "27200/27200 [==============================] - 16s 570us/step - loss: 0.1952 - acc: 0.9335 - val_loss: 0.8618 - val_acc: 0.8063\n",
      "Epoch 22/25\n",
      "27200/27200 [==============================] - 17s 610us/step - loss: 0.1855 - acc: 0.9381 - val_loss: 1.0298 - val_acc: 0.7953\n",
      "Epoch 23/25\n",
      "27200/27200 [==============================] - 16s 601us/step - loss: 0.1835 - acc: 0.9385 - val_loss: 0.9232 - val_acc: 0.8128\n",
      "Epoch 24/25\n",
      "27200/27200 [==============================] - 16s 605us/step - loss: 0.1643 - acc: 0.9447 - val_loss: 0.9122 - val_acc: 0.8213\n",
      "Epoch 25/25\n",
      "27200/27200 [==============================] - 16s 602us/step - loss: 0.1585 - acc: 0.9472 - val_loss: 1.1059 - val_acc: 0.7910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7febf87a9110>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model20 = model_spnet()\n",
    "model20.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27200 samples, validate on 6800 samples\n",
      "Epoch 1/25\n",
      "27200/27200 [==============================] - 16s 578us/step - loss: 2.3838 - acc: 0.2635 - val_loss: 1.6887 - val_acc: 0.4504\n",
      "Epoch 2/25\n",
      "27200/27200 [==============================] - 14s 517us/step - loss: 1.3800 - acc: 0.5595 - val_loss: 1.1711 - val_acc: 0.6324\n",
      "Epoch 3/25\n",
      "27200/27200 [==============================] - 16s 592us/step - loss: 0.9898 - acc: 0.6887 - val_loss: 0.9036 - val_acc: 0.7182\n",
      "Epoch 4/25\n",
      "27200/27200 [==============================] - 17s 628us/step - loss: 0.8207 - acc: 0.7418 - val_loss: 0.8048 - val_acc: 0.7476\n",
      "Epoch 5/25\n",
      "27200/27200 [==============================] - 19s 713us/step - loss: 0.7021 - acc: 0.7775 - val_loss: 0.7576 - val_acc: 0.7662\n",
      "Epoch 6/25\n",
      "27200/27200 [==============================] - 15s 563us/step - loss: 0.6384 - acc: 0.8002 - val_loss: 0.7258 - val_acc: 0.7749\n",
      "Epoch 7/25\n",
      "27200/27200 [==============================] - 16s 604us/step - loss: 0.5732 - acc: 0.8206 - val_loss: 0.7207 - val_acc: 0.7831\n",
      "Epoch 8/25\n",
      "27200/27200 [==============================] - 14s 531us/step - loss: 0.5264 - acc: 0.8325 - val_loss: 0.7116 - val_acc: 0.7850\n",
      "Epoch 9/25\n",
      "27200/27200 [==============================] - 16s 592us/step - loss: 0.4748 - acc: 0.8468 - val_loss: 0.7699 - val_acc: 0.7788\n",
      "Epoch 10/25\n",
      "27200/27200 [==============================] - 16s 578us/step - loss: 0.4427 - acc: 0.8577 - val_loss: 0.6285 - val_acc: 0.8151\n",
      "Epoch 11/25\n",
      "27200/27200 [==============================] - 15s 539us/step - loss: 0.4121 - acc: 0.8667 - val_loss: 0.6700 - val_acc: 0.8043\n",
      "Epoch 12/25\n",
      "27200/27200 [==============================] - 13s 469us/step - loss: 0.3820 - acc: 0.8746 - val_loss: 0.6552 - val_acc: 0.8071\n",
      "Epoch 13/25\n",
      "27200/27200 [==============================] - 15s 547us/step - loss: 0.3628 - acc: 0.8841 - val_loss: 0.8201 - val_acc: 0.7875\n",
      "Epoch 14/25\n",
      "27200/27200 [==============================] - 14s 498us/step - loss: 0.3267 - acc: 0.8931 - val_loss: 0.6946 - val_acc: 0.8060\n",
      "Epoch 15/25\n",
      "27200/27200 [==============================] - 15s 564us/step - loss: 0.3044 - acc: 0.8991 - val_loss: 0.7775 - val_acc: 0.7868\n",
      "Epoch 16/25\n",
      "27200/27200 [==============================] - 15s 545us/step - loss: 0.2896 - acc: 0.9054 - val_loss: 0.9621 - val_acc: 0.7818\n",
      "Epoch 17/25\n",
      "27200/27200 [==============================] - 14s 520us/step - loss: 0.2640 - acc: 0.9138 - val_loss: 0.8637 - val_acc: 0.7924\n",
      "Epoch 18/25\n",
      "27200/27200 [==============================] - 14s 523us/step - loss: 0.2544 - acc: 0.9144 - val_loss: 0.7781 - val_acc: 0.8101\n",
      "Epoch 19/25\n",
      "27200/27200 [==============================] - 15s 536us/step - loss: 0.2263 - acc: 0.9252 - val_loss: 0.7957 - val_acc: 0.8182\n",
      "Epoch 20/25\n",
      "27200/27200 [==============================] - 14s 510us/step - loss: 0.2176 - acc: 0.9262 - val_loss: 0.8596 - val_acc: 0.8099\n",
      "Epoch 21/25\n",
      "27200/27200 [==============================] - 14s 529us/step - loss: 0.1981 - acc: 0.9321 - val_loss: 0.8415 - val_acc: 0.8093\n",
      "Epoch 22/25\n",
      "27200/27200 [==============================] - 14s 526us/step - loss: 0.1893 - acc: 0.9374 - val_loss: 0.8867 - val_acc: 0.8163\n",
      "Epoch 23/25\n",
      "27200/27200 [==============================] - 15s 565us/step - loss: 0.1874 - acc: 0.9380 - val_loss: 0.8597 - val_acc: 0.8229\n",
      "Epoch 24/25\n",
      "27200/27200 [==============================] - 17s 632us/step - loss: 0.1595 - acc: 0.9447 - val_loss: 0.9090 - val_acc: 0.8175\n",
      "Epoch 25/25\n",
      "27200/27200 [==============================] - 18s 663us/step - loss: 0.1626 - acc: 0.9459 - val_loss: 1.0697 - val_acc: 0.7906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feba2507e10>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model26 = model_spnet()\n",
    "model26.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_spnet2():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(20, kernel_size=(2, 2),strides=1, input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(Conv2D(50, kernel_size=(2, 2)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(ZeroPadding2D(padding=(2,2)))\n",
    "    model.add(Conv2D(50, kernel_size=(2, 2), strides=1))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27200 samples, validate on 6800 samples\n",
      "Epoch 1/25\n",
      "27200/27200 [==============================] - 6s 209us/step - loss: 2.7862 - acc: 0.1771 - val_loss: 2.1823 - val_acc: 0.3109\n",
      "Epoch 2/25\n",
      "27200/27200 [==============================] - 6s 210us/step - loss: 2.0087 - acc: 0.3707 - val_loss: 1.8195 - val_acc: 0.4222\n",
      "Epoch 3/25\n",
      "27200/27200 [==============================] - 5s 181us/step - loss: 1.6870 - acc: 0.4696 - val_loss: 1.6139 - val_acc: 0.4931\n",
      "Epoch 4/25\n",
      "27200/27200 [==============================] - 5s 183us/step - loss: 1.4817 - acc: 0.5327 - val_loss: 1.3839 - val_acc: 0.5604\n",
      "Epoch 5/25\n",
      "27200/27200 [==============================] - 5s 193us/step - loss: 1.3498 - acc: 0.5764 - val_loss: 1.3188 - val_acc: 0.5881\n",
      "Epoch 6/25\n",
      "27200/27200 [==============================] - 5s 191us/step - loss: 1.2398 - acc: 0.6081 - val_loss: 1.2913 - val_acc: 0.5934\n",
      "Epoch 7/25\n",
      "27200/27200 [==============================] - 5s 189us/step - loss: 1.1753 - acc: 0.6264 - val_loss: 1.2446 - val_acc: 0.6181\n",
      "Epoch 8/25\n",
      "27200/27200 [==============================] - 5s 184us/step - loss: 1.1052 - acc: 0.6499 - val_loss: 1.1399 - val_acc: 0.6390\n",
      "Epoch 9/25\n",
      "27200/27200 [==============================] - 5s 185us/step - loss: 1.0481 - acc: 0.6692 - val_loss: 1.2078 - val_acc: 0.6179\n",
      "Epoch 10/25\n",
      "27200/27200 [==============================] - 5s 184us/step - loss: 1.0036 - acc: 0.6819 - val_loss: 1.1208 - val_acc: 0.6575\n",
      "Epoch 11/25\n",
      "27200/27200 [==============================] - 5s 188us/step - loss: 0.9677 - acc: 0.6954 - val_loss: 1.0747 - val_acc: 0.6678\n",
      "Epoch 12/25\n",
      "27200/27200 [==============================] - 5s 182us/step - loss: 0.9169 - acc: 0.7085 - val_loss: 1.0114 - val_acc: 0.6857\n",
      "Epoch 13/25\n",
      "27200/27200 [==============================] - 5s 188us/step - loss: 0.8797 - acc: 0.7230 - val_loss: 1.0033 - val_acc: 0.6890\n",
      "Epoch 14/25\n",
      "27200/27200 [==============================] - 5s 182us/step - loss: 0.8632 - acc: 0.7271 - val_loss: 0.9872 - val_acc: 0.6934\n",
      "Epoch 15/25\n",
      "27200/27200 [==============================] - 5s 183us/step - loss: 0.8309 - acc: 0.7377 - val_loss: 1.0614 - val_acc: 0.6715\n",
      "Epoch 16/25\n",
      "27200/27200 [==============================] - 5s 187us/step - loss: 0.8028 - acc: 0.7436 - val_loss: 1.0818 - val_acc: 0.6687\n",
      "Epoch 17/25\n",
      "27200/27200 [==============================] - 5s 194us/step - loss: 0.7787 - acc: 0.7521 - val_loss: 0.9846 - val_acc: 0.6981\n",
      "Epoch 18/25\n",
      "27200/27200 [==============================] - 5s 182us/step - loss: 0.7538 - acc: 0.7573 - val_loss: 0.9579 - val_acc: 0.7049\n",
      "Epoch 19/25\n",
      "27200/27200 [==============================] - 5s 177us/step - loss: 0.7328 - acc: 0.7666 - val_loss: 1.0773 - val_acc: 0.6757\n",
      "Epoch 20/25\n",
      "27200/27200 [==============================] - 5s 182us/step - loss: 0.7185 - acc: 0.7696 - val_loss: 0.9816 - val_acc: 0.7062\n",
      "Epoch 21/25\n",
      "27200/27200 [==============================] - 5s 178us/step - loss: 0.6984 - acc: 0.7768 - val_loss: 1.0058 - val_acc: 0.7040\n",
      "Epoch 22/25\n",
      "27200/27200 [==============================] - 5s 182us/step - loss: 0.6774 - acc: 0.7799 - val_loss: 0.9913 - val_acc: 0.7082\n",
      "Epoch 23/25\n",
      "27200/27200 [==============================] - 5s 180us/step - loss: 0.6648 - acc: 0.7868 - val_loss: 0.9124 - val_acc: 0.7290\n",
      "Epoch 24/25\n",
      "27200/27200 [==============================] - 5s 188us/step - loss: 0.6380 - acc: 0.7928 - val_loss: 0.9751 - val_acc: 0.7172\n",
      "Epoch 25/25\n",
      "27200/27200 [==============================] - 5s 187us/step - loss: 0.6377 - acc: 0.7943 - val_loss: 0.9253 - val_acc: 0.7266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feba3facb10>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model13 = model_spnet2()\n",
    "model13.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27200 samples, validate on 6800 samples\n",
      "Epoch 1/25\n",
      "27200/27200 [==============================] - 10s 359us/step - loss: 3.2945 - acc: 0.1978 - val_loss: 2.0767 - val_acc: 0.3543\n",
      "Epoch 2/25\n",
      "27200/27200 [==============================] - 9s 326us/step - loss: 1.8901 - acc: 0.4147 - val_loss: 1.6500 - val_acc: 0.4888\n",
      "Epoch 3/25\n",
      "27200/27200 [==============================] - 9s 348us/step - loss: 1.5344 - acc: 0.5235 - val_loss: 1.3886 - val_acc: 0.5579\n",
      "Epoch 4/25\n",
      "27200/27200 [==============================] - 9s 336us/step - loss: 1.3292 - acc: 0.5869 - val_loss: 1.4646 - val_acc: 0.5409\n",
      "Epoch 5/25\n",
      "27200/27200 [==============================] - 9s 320us/step - loss: 1.2005 - acc: 0.6253 - val_loss: 1.1842 - val_acc: 0.6341\n",
      "Epoch 6/25\n",
      "27200/27200 [==============================] - 9s 313us/step - loss: 1.1038 - acc: 0.6548 - val_loss: 1.1475 - val_acc: 0.6406\n",
      "Epoch 7/25\n",
      "27200/27200 [==============================] - 9s 340us/step - loss: 1.0257 - acc: 0.6807 - val_loss: 1.1150 - val_acc: 0.6381\n",
      "Epoch 8/25\n",
      "27200/27200 [==============================] - 9s 337us/step - loss: 0.9650 - acc: 0.6952 - val_loss: 1.0055 - val_acc: 0.6806\n",
      "Epoch 9/25\n",
      "27200/27200 [==============================] - 9s 328us/step - loss: 0.9077 - acc: 0.7153 - val_loss: 0.9569 - val_acc: 0.6978\n",
      "Epoch 10/25\n",
      "27200/27200 [==============================] - 9s 338us/step - loss: 0.8460 - acc: 0.7306 - val_loss: 0.9619 - val_acc: 0.7001\n",
      "Epoch 11/25\n",
      "27200/27200 [==============================] - 10s 375us/step - loss: 0.8196 - acc: 0.7408 - val_loss: 0.9429 - val_acc: 0.7107\n",
      "Epoch 12/25\n",
      "27200/27200 [==============================] - 10s 376us/step - loss: 0.7790 - acc: 0.7539 - val_loss: 0.9469 - val_acc: 0.7138\n",
      "Epoch 13/25\n",
      "27200/27200 [==============================] - 9s 339us/step - loss: 0.7372 - acc: 0.7654 - val_loss: 1.1385 - val_acc: 0.6616\n",
      "Epoch 14/25\n",
      "27200/27200 [==============================] - 9s 335us/step - loss: 0.7140 - acc: 0.7725 - val_loss: 1.0027 - val_acc: 0.6969\n",
      "Epoch 15/25\n",
      "27200/27200 [==============================] - 9s 340us/step - loss: 0.6798 - acc: 0.7838 - val_loss: 0.9303 - val_acc: 0.7185\n",
      "Epoch 16/25\n",
      "27200/27200 [==============================] - 9s 338us/step - loss: 0.6487 - acc: 0.7894 - val_loss: 1.0275 - val_acc: 0.7074\n",
      "Epoch 17/25\n",
      "27200/27200 [==============================] - 9s 345us/step - loss: 0.6235 - acc: 0.7984 - val_loss: 0.8990 - val_acc: 0.7328\n",
      "Epoch 18/25\n",
      "27200/27200 [==============================] - 10s 378us/step - loss: 0.6096 - acc: 0.8031 - val_loss: 0.8908 - val_acc: 0.7276\n",
      "Epoch 19/25\n",
      "27200/27200 [==============================] - 8s 279us/step - loss: 0.5784 - acc: 0.8112 - val_loss: 0.9409 - val_acc: 0.7240\n",
      "Epoch 20/25\n",
      "27200/27200 [==============================] - 8s 279us/step - loss: 0.5588 - acc: 0.8190 - val_loss: 0.9489 - val_acc: 0.7249\n",
      "Epoch 21/25\n",
      "27200/27200 [==============================] - 8s 277us/step - loss: 0.5396 - acc: 0.8232 - val_loss: 0.9654 - val_acc: 0.7234\n",
      "Epoch 22/25\n",
      "27200/27200 [==============================] - 9s 325us/step - loss: 0.5267 - acc: 0.8283 - val_loss: 0.9440 - val_acc: 0.7304\n",
      "Epoch 23/25\n",
      "27200/27200 [==============================] - 8s 299us/step - loss: 0.4960 - acc: 0.8383 - val_loss: 1.0296 - val_acc: 0.7160\n",
      "Epoch 24/25\n",
      "27200/27200 [==============================] - 8s 302us/step - loss: 0.4784 - acc: 0.8428 - val_loss: 0.9856 - val_acc: 0.7303\n",
      "Epoch 25/25\n",
      "27200/27200 [==============================] - 9s 313us/step - loss: 0.4666 - acc: 0.8468 - val_loss: 0.9550 - val_acc: 0.7319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feba46c9490>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model20 = model_spnet2()\n",
    "model20.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27200 samples, validate on 6800 samples\n",
      "Epoch 1/25\n",
      "27200/27200 [==============================] - 8s 310us/step - loss: 2.8062 - acc: 0.2125 - val_loss: 2.0745 - val_acc: 0.3316\n",
      "Epoch 2/25\n",
      "27200/27200 [==============================] - 8s 282us/step - loss: 1.8486 - acc: 0.4147 - val_loss: 1.7484 - val_acc: 0.4343\n",
      "Epoch 3/25\n",
      "27200/27200 [==============================] - 9s 330us/step - loss: 1.4802 - acc: 0.5322 - val_loss: 1.5198 - val_acc: 0.5372\n",
      "Epoch 4/25\n",
      "27200/27200 [==============================] - 8s 288us/step - loss: 1.2739 - acc: 0.5969 - val_loss: 1.3293 - val_acc: 0.5903\n",
      "Epoch 5/25\n",
      "27200/27200 [==============================] - 9s 347us/step - loss: 1.1339 - acc: 0.6430 - val_loss: 1.3139 - val_acc: 0.5896\n",
      "Epoch 6/25\n",
      "27200/27200 [==============================] - 9s 324us/step - loss: 1.0222 - acc: 0.6730 - val_loss: 1.1224 - val_acc: 0.6534\n",
      "Epoch 7/25\n",
      "27200/27200 [==============================] - 9s 345us/step - loss: 0.9506 - acc: 0.6998 - val_loss: 1.0289 - val_acc: 0.6885\n",
      "Epoch 8/25\n",
      "27200/27200 [==============================] - 9s 314us/step - loss: 0.8832 - acc: 0.7200 - val_loss: 1.0359 - val_acc: 0.6800\n",
      "Epoch 9/25\n",
      "27200/27200 [==============================] - 8s 278us/step - loss: 0.8373 - acc: 0.7339 - val_loss: 0.9791 - val_acc: 0.7021\n",
      "Epoch 10/25\n",
      "27200/27200 [==============================] - 8s 292us/step - loss: 0.7828 - acc: 0.7509 - val_loss: 1.0338 - val_acc: 0.6828\n",
      "Epoch 11/25\n",
      "27200/27200 [==============================] - 9s 338us/step - loss: 0.7391 - acc: 0.7632 - val_loss: 0.9642 - val_acc: 0.7093\n",
      "Epoch 12/25\n",
      "27200/27200 [==============================] - 8s 299us/step - loss: 0.7073 - acc: 0.7736 - val_loss: 1.0672 - val_acc: 0.6782\n",
      "Epoch 13/25\n",
      "27200/27200 [==============================] - 9s 315us/step - loss: 0.6685 - acc: 0.7857 - val_loss: 0.8994 - val_acc: 0.7271\n",
      "Epoch 14/25\n",
      "27200/27200 [==============================] - 8s 304us/step - loss: 0.6365 - acc: 0.7925 - val_loss: 0.9102 - val_acc: 0.7294\n",
      "Epoch 15/25\n",
      "27200/27200 [==============================] - 8s 299us/step - loss: 0.6029 - acc: 0.8048 - val_loss: 0.9408 - val_acc: 0.7203\n",
      "Epoch 16/25\n",
      "27200/27200 [==============================] - 9s 339us/step - loss: 0.5829 - acc: 0.8092 - val_loss: 0.9209 - val_acc: 0.7293\n",
      "Epoch 17/25\n",
      "27200/27200 [==============================] - 10s 353us/step - loss: 0.5500 - acc: 0.8178 - val_loss: 0.9228 - val_acc: 0.7337\n",
      "Epoch 18/25\n",
      "27200/27200 [==============================] - 8s 287us/step - loss: 0.5278 - acc: 0.8259 - val_loss: 1.0435 - val_acc: 0.7035\n",
      "Epoch 19/25\n",
      "27200/27200 [==============================] - 8s 306us/step - loss: 0.5060 - acc: 0.8351 - val_loss: 0.8835 - val_acc: 0.7440\n",
      "Epoch 20/25\n",
      "27200/27200 [==============================] - 8s 283us/step - loss: 0.4832 - acc: 0.8412 - val_loss: 0.9198 - val_acc: 0.7425\n",
      "Epoch 21/25\n",
      "27200/27200 [==============================] - 10s 386us/step - loss: 0.4546 - acc: 0.8483 - val_loss: 0.9453 - val_acc: 0.7379\n",
      "Epoch 22/25\n",
      "27200/27200 [==============================] - 9s 332us/step - loss: 0.4354 - acc: 0.8564 - val_loss: 0.9137 - val_acc: 0.7453\n",
      "Epoch 23/25\n",
      "27200/27200 [==============================] - 10s 360us/step - loss: 0.4217 - acc: 0.8574 - val_loss: 0.9933 - val_acc: 0.7313\n",
      "Epoch 24/25\n",
      "27200/27200 [==============================] - 8s 304us/step - loss: 0.4011 - acc: 0.8655 - val_loss: 1.1074 - val_acc: 0.7221\n",
      "Epoch 25/25\n",
      "27200/27200 [==============================] - 11s 389us/step - loss: 0.3771 - acc: 0.8742 - val_loss: 1.1355 - val_acc: 0.7071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feba1f18fd0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model26 = model_spnet2()\n",
    "model26.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_spnet3():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(20, kernel_size=(3, 3),strides=1, input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(ZeroPadding2D(padding=(2,2)))\n",
    "    model.add(Conv2D(50, kernel_size=(3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(ZeroPadding2D(padding=(2,2)))\n",
    "    model.add(Conv2D(50, kernel_size=(3, 3), strides=1))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27200 samples, validate on 6800 samples\n",
      "Epoch 1/25\n",
      "27200/27200 [==============================] - 9s 342us/step - loss: 2.7971 - acc: 0.2563 - val_loss: 1.7387 - val_acc: 0.4546\n",
      "Epoch 2/25\n",
      "27200/27200 [==============================] - 9s 348us/step - loss: 1.4898 - acc: 0.5404 - val_loss: 1.4568 - val_acc: 0.5575\n",
      "Epoch 3/25\n",
      "27200/27200 [==============================] - 9s 332us/step - loss: 1.1135 - acc: 0.6522 - val_loss: 1.0192 - val_acc: 0.6838\n",
      "Epoch 4/25\n",
      "27200/27200 [==============================] - 9s 325us/step - loss: 0.9248 - acc: 0.7137 - val_loss: 1.0792 - val_acc: 0.6726\n",
      "Epoch 5/25\n",
      "27200/27200 [==============================] - 9s 349us/step - loss: 0.8054 - acc: 0.7487 - val_loss: 0.8977 - val_acc: 0.7249\n",
      "Epoch 6/25\n",
      "27200/27200 [==============================] - 10s 361us/step - loss: 0.7245 - acc: 0.7720 - val_loss: 0.7742 - val_acc: 0.7615\n",
      "Epoch 7/25\n",
      "27200/27200 [==============================] - 10s 370us/step - loss: 0.6518 - acc: 0.7940 - val_loss: 0.8827 - val_acc: 0.7337\n",
      "Epoch 8/25\n",
      "27200/27200 [==============================] - 9s 337us/step - loss: 0.6055 - acc: 0.8075 - val_loss: 0.8428 - val_acc: 0.7451\n",
      "Epoch 9/25\n",
      "27200/27200 [==============================] - 10s 365us/step - loss: 0.5565 - acc: 0.8239 - val_loss: 0.9185 - val_acc: 0.7379\n",
      "Epoch 10/25\n",
      "27200/27200 [==============================] - 9s 348us/step - loss: 0.5086 - acc: 0.8386 - val_loss: 0.7065 - val_acc: 0.8001\n",
      "Epoch 11/25\n",
      "27200/27200 [==============================] - 9s 318us/step - loss: 0.4798 - acc: 0.8459 - val_loss: 0.7647 - val_acc: 0.7809\n",
      "Epoch 12/25\n",
      "27200/27200 [==============================] - 9s 318us/step - loss: 0.4409 - acc: 0.8571 - val_loss: 0.7656 - val_acc: 0.7816\n",
      "Epoch 13/25\n",
      "27200/27200 [==============================] - 9s 339us/step - loss: 0.4239 - acc: 0.8630 - val_loss: 0.6998 - val_acc: 0.7996\n",
      "Epoch 14/25\n",
      "27200/27200 [==============================] - 12s 425us/step - loss: 0.3962 - acc: 0.8715 - val_loss: 0.7521 - val_acc: 0.7913\n",
      "Epoch 15/25\n",
      "27200/27200 [==============================] - 12s 446us/step - loss: 0.3671 - acc: 0.8800 - val_loss: 0.7339 - val_acc: 0.7978\n",
      "Epoch 16/25\n",
      "27200/27200 [==============================] - 10s 353us/step - loss: 0.3392 - acc: 0.8883 - val_loss: 0.7325 - val_acc: 0.8037\n",
      "Epoch 17/25\n",
      "27200/27200 [==============================] - 11s 392us/step - loss: 0.3235 - acc: 0.8932 - val_loss: 0.8946 - val_acc: 0.7791\n",
      "Epoch 18/25\n",
      "27200/27200 [==============================] - 9s 346us/step - loss: 0.2999 - acc: 0.9006 - val_loss: 0.7378 - val_acc: 0.8060\n",
      "Epoch 19/25\n",
      "27200/27200 [==============================] - 11s 401us/step - loss: 0.2822 - acc: 0.9064 - val_loss: 0.7902 - val_acc: 0.7954\n",
      "Epoch 20/25\n",
      "27200/27200 [==============================] - 10s 362us/step - loss: 0.2551 - acc: 0.9139 - val_loss: 0.7844 - val_acc: 0.8078\n",
      "Epoch 21/25\n",
      "27200/27200 [==============================] - 9s 335us/step - loss: 0.2429 - acc: 0.9189 - val_loss: 0.8765 - val_acc: 0.7882\n",
      "Epoch 22/25\n",
      "27200/27200 [==============================] - 10s 356us/step - loss: 0.2282 - acc: 0.9250 - val_loss: 0.9047 - val_acc: 0.7919\n",
      "Epoch 23/25\n",
      "27200/27200 [==============================] - 11s 410us/step - loss: 0.2135 - acc: 0.9278 - val_loss: 0.8713 - val_acc: 0.8059\n",
      "Epoch 24/25\n",
      "27200/27200 [==============================] - 10s 354us/step - loss: 0.1972 - acc: 0.9315 - val_loss: 0.9039 - val_acc: 0.7990\n",
      "Epoch 25/25\n",
      "27200/27200 [==============================] - 10s 371us/step - loss: 0.1869 - acc: 0.9364 - val_loss: 0.9449 - val_acc: 0.7984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feba39d8f90>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model13 = model_spnet3()\n",
    "model13.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27200 samples, validate on 6800 samples\n",
      "Epoch 1/25\n",
      "27200/27200 [==============================] - 15s 546us/step - loss: 2.7685 - acc: 0.2657 - val_loss: 1.7727 - val_acc: 0.4478\n",
      "Epoch 2/25\n",
      "27200/27200 [==============================] - 14s 507us/step - loss: 1.5121 - acc: 0.5290 - val_loss: 1.5148 - val_acc: 0.5331\n",
      "Epoch 3/25\n",
      "27200/27200 [==============================] - 14s 519us/step - loss: 1.1448 - acc: 0.6441 - val_loss: 1.1323 - val_acc: 0.6443\n",
      "Epoch 4/25\n",
      "27200/27200 [==============================] - 14s 530us/step - loss: 0.9401 - acc: 0.7033 - val_loss: 0.8627 - val_acc: 0.7322\n",
      "Epoch 5/25\n",
      "27200/27200 [==============================] - 16s 582us/step - loss: 0.8111 - acc: 0.7471 - val_loss: 0.8817 - val_acc: 0.7291\n",
      "Epoch 6/25\n",
      "27200/27200 [==============================] - 15s 554us/step - loss: 0.7222 - acc: 0.7728 - val_loss: 0.8730 - val_acc: 0.7326\n",
      "Epoch 7/25\n",
      "27200/27200 [==============================] - 15s 568us/step - loss: 0.6456 - acc: 0.7953 - val_loss: 0.7205 - val_acc: 0.7829\n",
      "Epoch 8/25\n",
      "27200/27200 [==============================] - 15s 542us/step - loss: 0.5819 - acc: 0.8124 - val_loss: 0.8059 - val_acc: 0.7600\n",
      "Epoch 9/25\n",
      "27200/27200 [==============================] - 15s 543us/step - loss: 0.5287 - acc: 0.8286 - val_loss: 0.7769 - val_acc: 0.7712\n",
      "Epoch 10/25\n",
      "27200/27200 [==============================] - 15s 563us/step - loss: 0.4842 - acc: 0.8416 - val_loss: 0.7414 - val_acc: 0.7746\n",
      "Epoch 11/25\n",
      "27200/27200 [==============================] - 16s 572us/step - loss: 0.4474 - acc: 0.8538 - val_loss: 0.7311 - val_acc: 0.7824\n",
      "Epoch 12/25\n",
      "27200/27200 [==============================] - 15s 567us/step - loss: 0.4030 - acc: 0.8654 - val_loss: 0.7426 - val_acc: 0.7876\n",
      "Epoch 13/25\n",
      "27200/27200 [==============================] - 16s 573us/step - loss: 0.3725 - acc: 0.8765 - val_loss: 0.7624 - val_acc: 0.7862\n",
      "Epoch 14/25\n",
      "27200/27200 [==============================] - 15s 550us/step - loss: 0.3467 - acc: 0.8865 - val_loss: 0.7913 - val_acc: 0.7835\n",
      "Epoch 15/25\n",
      "27200/27200 [==============================] - 14s 526us/step - loss: 0.3165 - acc: 0.8951 - val_loss: 0.7692 - val_acc: 0.7903\n",
      "Epoch 16/25\n",
      "27200/27200 [==============================] - 15s 552us/step - loss: 0.2964 - acc: 0.9010 - val_loss: 0.8178 - val_acc: 0.7831\n",
      "Epoch 17/25\n",
      "27200/27200 [==============================] - 16s 583us/step - loss: 0.2681 - acc: 0.9101 - val_loss: 0.8428 - val_acc: 0.7835\n",
      "Epoch 18/25\n",
      "27200/27200 [==============================] - 16s 572us/step - loss: 0.2434 - acc: 0.9167 - val_loss: 0.9743 - val_acc: 0.7638\n",
      "Epoch 19/25\n",
      "27200/27200 [==============================] - 16s 574us/step - loss: 0.2230 - acc: 0.9247 - val_loss: 0.8977 - val_acc: 0.7829\n",
      "Epoch 20/25\n",
      "27200/27200 [==============================] - 15s 540us/step - loss: 0.2078 - acc: 0.9296 - val_loss: 0.9216 - val_acc: 0.7882\n",
      "Epoch 21/25\n",
      "27200/27200 [==============================] - 16s 582us/step - loss: 0.1933 - acc: 0.9348 - val_loss: 0.9382 - val_acc: 0.7859\n",
      "Epoch 22/25\n",
      "27200/27200 [==============================] - 15s 537us/step - loss: 0.1657 - acc: 0.9437 - val_loss: 0.9624 - val_acc: 0.7853\n",
      "Epoch 23/25\n",
      "27200/27200 [==============================] - 16s 582us/step - loss: 0.1694 - acc: 0.9439 - val_loss: 0.9812 - val_acc: 0.7897\n",
      "Epoch 24/25\n",
      "27200/27200 [==============================] - 18s 674us/step - loss: 0.1547 - acc: 0.9483 - val_loss: 1.0374 - val_acc: 0.7849\n",
      "Epoch 25/25\n",
      "27200/27200 [==============================] - 15s 543us/step - loss: 0.1409 - acc: 0.9528 - val_loss: 1.0343 - val_acc: 0.7921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f46918d0fd0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model20 = model_spnet3()\n",
    "model20.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27200 samples, validate on 6800 samples\n",
      "Epoch 1/25\n",
      "27200/27200 [==============================] - 18s 659us/step - loss: 5.3215 - acc: 0.1829 - val_loss: 1.8196 - val_acc: 0.4418\n",
      "Epoch 2/25\n",
      "27200/27200 [==============================] - 17s 613us/step - loss: 1.6489 - acc: 0.4871 - val_loss: 1.4021 - val_acc: 0.5456\n",
      "Epoch 3/25\n",
      "27200/27200 [==============================] - 19s 692us/step - loss: 1.1944 - acc: 0.6254 - val_loss: 1.1350 - val_acc: 0.6438\n",
      "Epoch 4/25\n",
      "27200/27200 [==============================] - 17s 611us/step - loss: 0.9652 - acc: 0.6973 - val_loss: 1.0271 - val_acc: 0.6781\n",
      "Epoch 5/25\n",
      "27200/27200 [==============================] - 17s 613us/step - loss: 0.8258 - acc: 0.7401 - val_loss: 0.8822 - val_acc: 0.7250\n",
      "Epoch 6/25\n",
      "27200/27200 [==============================] - 19s 685us/step - loss: 0.7277 - acc: 0.7687 - val_loss: 0.8767 - val_acc: 0.7285\n",
      "Epoch 7/25\n",
      "27200/27200 [==============================] - 19s 688us/step - loss: 0.6399 - acc: 0.7969 - val_loss: 0.8131 - val_acc: 0.7500\n",
      "Epoch 8/25\n",
      "27200/27200 [==============================] - 19s 693us/step - loss: 0.5741 - acc: 0.8138 - val_loss: 0.7382 - val_acc: 0.7746\n",
      "Epoch 9/25\n",
      "27200/27200 [==============================] - 19s 684us/step - loss: 0.5229 - acc: 0.8311 - val_loss: 0.7982 - val_acc: 0.7571\n",
      "Epoch 10/25\n",
      "27200/27200 [==============================] - 20s 718us/step - loss: 0.4638 - acc: 0.8497 - val_loss: 0.7584 - val_acc: 0.7731\n",
      "Epoch 11/25\n",
      "27200/27200 [==============================] - 17s 632us/step - loss: 0.4258 - acc: 0.8612 - val_loss: 0.7712 - val_acc: 0.7810\n",
      "Epoch 12/25\n",
      "27200/27200 [==============================] - 17s 629us/step - loss: 0.3843 - acc: 0.8721 - val_loss: 0.8466 - val_acc: 0.7668\n",
      "Epoch 13/25\n",
      "27200/27200 [==============================] - 19s 688us/step - loss: 0.3478 - acc: 0.8867 - val_loss: 0.7564 - val_acc: 0.7944\n",
      "Epoch 14/25\n",
      "27200/27200 [==============================] - 19s 691us/step - loss: 0.3207 - acc: 0.8930 - val_loss: 0.7855 - val_acc: 0.7846\n",
      "Epoch 15/25\n",
      "27200/27200 [==============================] - 19s 692us/step - loss: 0.2847 - acc: 0.9056 - val_loss: 0.8953 - val_acc: 0.7763\n",
      "Epoch 16/25\n",
      "27200/27200 [==============================] - 19s 694us/step - loss: 0.2596 - acc: 0.9138 - val_loss: 0.8319 - val_acc: 0.7915\n",
      "Epoch 17/25\n",
      "27200/27200 [==============================] - 19s 684us/step - loss: 0.2376 - acc: 0.9204 - val_loss: 0.8392 - val_acc: 0.7943\n",
      "Epoch 18/25\n",
      "27200/27200 [==============================] - 18s 672us/step - loss: 0.2179 - acc: 0.9264 - val_loss: 0.8681 - val_acc: 0.7931\n",
      "Epoch 19/25\n",
      "27200/27200 [==============================] - 22s 798us/step - loss: 0.1952 - acc: 0.9333 - val_loss: 0.8714 - val_acc: 0.7957\n",
      "Epoch 20/25\n",
      "27200/27200 [==============================] - 20s 752us/step - loss: 0.1768 - acc: 0.9400 - val_loss: 1.0159 - val_acc: 0.7834\n",
      "Epoch 21/25\n",
      "27200/27200 [==============================] - 20s 727us/step - loss: 0.1708 - acc: 0.9420 - val_loss: 1.0104 - val_acc: 0.7866\n",
      "Epoch 22/25\n",
      "27200/27200 [==============================] - 21s 764us/step - loss: 0.1483 - acc: 0.9485 - val_loss: 1.0000 - val_acc: 0.7941\n",
      "Epoch 23/25\n",
      "27200/27200 [==============================] - 21s 760us/step - loss: 0.1460 - acc: 0.9500 - val_loss: 1.0275 - val_acc: 0.7879\n",
      "Epoch 24/25\n",
      "27200/27200 [==============================] - 21s 783us/step - loss: 0.1379 - acc: 0.9549 - val_loss: 1.0331 - val_acc: 0.7891\n",
      "Epoch 25/25\n",
      "27200/27200 [==============================] - 21s 762us/step - loss: 0.1112 - acc: 0.9626 - val_loss: 1.1811 - val_acc: 0.7813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4699b15e50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model26 = model_spnet3()\n",
    "model26.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_spnet4():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(20, kernel_size=(4, 4),strides=1, input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(ZeroPadding2D(padding=(2,2)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(ZeroPadding2D(padding=(2,2)))\n",
    "    model.add(Conv2D(50, kernel_size=(4, 4)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(ZeroPadding2D(padding=(2,2)))\n",
    "    model.add(Conv2D(50, kernel_size=(4, 4), strides=1))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27200 samples, validate on 6800 samples\n",
      "Epoch 1/25\n",
      "27200/27200 [==============================] - 18s 654us/step - loss: 2.4992 - acc: 0.3001 - val_loss: 1.3191 - val_acc: 0.5838\n",
      "Epoch 2/25\n",
      "27200/27200 [==============================] - 15s 546us/step - loss: 1.2986 - acc: 0.5964 - val_loss: 0.9989 - val_acc: 0.6807\n",
      "Epoch 3/25\n",
      "27200/27200 [==============================] - 15s 549us/step - loss: 0.9199 - acc: 0.7108 - val_loss: 0.7384 - val_acc: 0.7693\n",
      "Epoch 4/25\n",
      "27200/27200 [==============================] - 15s 547us/step - loss: 0.7604 - acc: 0.7605 - val_loss: 0.7576 - val_acc: 0.7725\n",
      "Epoch 5/25\n",
      "27200/27200 [==============================] - 15s 548us/step - loss: 0.6562 - acc: 0.7926 - val_loss: 0.8204 - val_acc: 0.7541\n",
      "Epoch 6/25\n",
      "27200/27200 [==============================] - 18s 668us/step - loss: 0.5913 - acc: 0.8146 - val_loss: 0.6490 - val_acc: 0.8021\n",
      "Epoch 7/25\n",
      "27200/27200 [==============================] - 17s 634us/step - loss: 0.5101 - acc: 0.8364 - val_loss: 0.8364 - val_acc: 0.7526\n",
      "Epoch 8/25\n",
      "27200/27200 [==============================] - 17s 625us/step - loss: 0.4765 - acc: 0.8481 - val_loss: 0.6642 - val_acc: 0.8038\n",
      "Epoch 9/25\n",
      "27200/27200 [==============================] - 15s 563us/step - loss: 0.4174 - acc: 0.8665 - val_loss: 0.6494 - val_acc: 0.8103\n",
      "Epoch 10/25\n",
      "27200/27200 [==============================] - 18s 679us/step - loss: 0.3963 - acc: 0.8725 - val_loss: 0.6818 - val_acc: 0.8149\n",
      "Epoch 11/25\n",
      "27200/27200 [==============================] - 19s 711us/step - loss: 0.3408 - acc: 0.8887 - val_loss: 0.7199 - val_acc: 0.8047\n",
      "Epoch 12/25\n",
      "27200/27200 [==============================] - 20s 741us/step - loss: 0.3229 - acc: 0.8944 - val_loss: 0.7434 - val_acc: 0.8078\n",
      "Epoch 13/25\n",
      "27200/27200 [==============================] - 21s 760us/step - loss: 0.2864 - acc: 0.9060 - val_loss: 0.7920 - val_acc: 0.8034\n",
      "Epoch 14/25\n",
      "27200/27200 [==============================] - 17s 608us/step - loss: 0.2561 - acc: 0.9129 - val_loss: 0.7533 - val_acc: 0.8159\n",
      "Epoch 15/25\n",
      "27200/27200 [==============================] - 18s 650us/step - loss: 0.2314 - acc: 0.9236 - val_loss: 0.7335 - val_acc: 0.8246\n",
      "Epoch 16/25\n",
      "27200/27200 [==============================] - 20s 734us/step - loss: 0.2404 - acc: 0.9213 - val_loss: 0.7291 - val_acc: 0.8216\n",
      "Epoch 17/25\n",
      "27200/27200 [==============================] - 22s 825us/step - loss: 0.1972 - acc: 0.9335 - val_loss: 0.7636 - val_acc: 0.8274\n",
      "Epoch 18/25\n",
      "27200/27200 [==============================] - 20s 745us/step - loss: 0.1803 - acc: 0.9403 - val_loss: 0.7612 - val_acc: 0.8331\n",
      "Epoch 19/25\n",
      "27200/27200 [==============================] - 20s 737us/step - loss: 0.1770 - acc: 0.9424 - val_loss: 0.8137 - val_acc: 0.8290\n",
      "Epoch 20/25\n",
      "27200/27200 [==============================] - 19s 688us/step - loss: 0.1620 - acc: 0.9450 - val_loss: 0.8738 - val_acc: 0.8147\n",
      "Epoch 21/25\n",
      "27200/27200 [==============================] - 21s 785us/step - loss: 0.1656 - acc: 0.9450 - val_loss: 1.0290 - val_acc: 0.8051\n",
      "Epoch 22/25\n",
      "27200/27200 [==============================] - 16s 602us/step - loss: 0.1398 - acc: 0.9529 - val_loss: 0.9121 - val_acc: 0.8200\n",
      "Epoch 23/25\n",
      "27200/27200 [==============================] - 15s 545us/step - loss: 0.1267 - acc: 0.9582 - val_loss: 0.9573 - val_acc: 0.8172\n",
      "Epoch 24/25\n",
      "27200/27200 [==============================] - 16s 571us/step - loss: 0.1304 - acc: 0.9558 - val_loss: 1.0942 - val_acc: 0.7990\n",
      "Epoch 25/25\n",
      "27200/27200 [==============================] - 14s 533us/step - loss: 0.1226 - acc: 0.9602 - val_loss: 0.9619 - val_acc: 0.8181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feba337a990>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model13 = model_spnet4()\n",
    "model13.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27200 samples, validate on 6800 samples\n",
      "Epoch 1/25\n",
      "27200/27200 [==============================] - 20s 727us/step - loss: 3.6287 - acc: 0.2628 - val_loss: 1.5496 - val_acc: 0.5029\n",
      "Epoch 2/25\n",
      "27200/27200 [==============================] - 20s 725us/step - loss: 1.2677 - acc: 0.6039 - val_loss: 1.0486 - val_acc: 0.6762\n",
      "Epoch 3/25\n",
      "27200/27200 [==============================] - 20s 740us/step - loss: 0.8885 - acc: 0.7224 - val_loss: 0.8832 - val_acc: 0.7238\n",
      "Epoch 4/25\n",
      "27200/27200 [==============================] - 21s 776us/step - loss: 0.7033 - acc: 0.7809 - val_loss: 0.7298 - val_acc: 0.7751\n",
      "Epoch 5/25\n",
      "27200/27200 [==============================] - 19s 716us/step - loss: 0.5964 - acc: 0.8108 - val_loss: 0.7193 - val_acc: 0.7868\n",
      "Epoch 6/25\n",
      "27200/27200 [==============================] - 21s 755us/step - loss: 0.5215 - acc: 0.8343 - val_loss: 0.6752 - val_acc: 0.8043\n",
      "Epoch 7/25\n",
      "27200/27200 [==============================] - 21s 755us/step - loss: 0.4560 - acc: 0.8540 - val_loss: 0.6704 - val_acc: 0.8010\n",
      "Epoch 8/25\n",
      "27200/27200 [==============================] - 21s 769us/step - loss: 0.3994 - acc: 0.8739 - val_loss: 0.6545 - val_acc: 0.8057\n",
      "Epoch 9/25\n",
      "27200/27200 [==============================] - 21s 768us/step - loss: 0.3670 - acc: 0.8810 - val_loss: 0.6507 - val_acc: 0.8140\n",
      "Epoch 10/25\n",
      "27200/27200 [==============================] - 21s 783us/step - loss: 0.3239 - acc: 0.8961 - val_loss: 0.6496 - val_acc: 0.8185\n",
      "Epoch 11/25\n",
      "27200/27200 [==============================] - 21s 784us/step - loss: 0.2856 - acc: 0.9062 - val_loss: 0.6137 - val_acc: 0.8260\n",
      "Epoch 12/25\n",
      "27200/27200 [==============================] - 22s 807us/step - loss: 0.2673 - acc: 0.9121 - val_loss: 0.6835 - val_acc: 0.8297\n",
      "Epoch 13/25\n",
      "27200/27200 [==============================] - 20s 741us/step - loss: 0.2332 - acc: 0.9221 - val_loss: 0.7718 - val_acc: 0.8151\n",
      "Epoch 14/25\n",
      "27200/27200 [==============================] - 23s 848us/step - loss: 0.2054 - acc: 0.9317 - val_loss: 0.7257 - val_acc: 0.8271\n",
      "Epoch 15/25\n",
      "27200/27200 [==============================] - 21s 755us/step - loss: 0.1964 - acc: 0.9350 - val_loss: 0.7870 - val_acc: 0.8244\n",
      "Epoch 16/25\n",
      "27200/27200 [==============================] - 19s 700us/step - loss: 0.1710 - acc: 0.9428 - val_loss: 0.7340 - val_acc: 0.8285\n",
      "Epoch 17/25\n",
      "27200/27200 [==============================] - 21s 781us/step - loss: 0.1685 - acc: 0.9439 - val_loss: 0.8004 - val_acc: 0.8282\n",
      "Epoch 18/25\n",
      "27200/27200 [==============================] - 22s 806us/step - loss: 0.1515 - acc: 0.9513 - val_loss: 0.7858 - val_acc: 0.8278\n",
      "Epoch 19/25\n",
      "27200/27200 [==============================] - 24s 880us/step - loss: 0.1468 - acc: 0.9533 - val_loss: 0.9211 - val_acc: 0.8175\n",
      "Epoch 20/25\n",
      "27200/27200 [==============================] - 21s 788us/step - loss: 0.1237 - acc: 0.9598 - val_loss: 0.8794 - val_acc: 0.8232\n",
      "Epoch 21/25\n",
      "27200/27200 [==============================] - 23s 858us/step - loss: 0.1218 - acc: 0.9605 - val_loss: 1.0528 - val_acc: 0.8121\n",
      "Epoch 22/25\n",
      "27200/27200 [==============================] - 22s 823us/step - loss: 0.1051 - acc: 0.9650 - val_loss: 1.0680 - val_acc: 0.8076\n",
      "Epoch 23/25\n",
      "27200/27200 [==============================] - 22s 793us/step - loss: 0.1210 - acc: 0.9621 - val_loss: 0.9156 - val_acc: 0.8388\n",
      "Epoch 24/25\n",
      "27200/27200 [==============================] - 24s 890us/step - loss: 0.1023 - acc: 0.9674 - val_loss: 0.9543 - val_acc: 0.8294\n",
      "Epoch 25/25\n",
      "27200/27200 [==============================] - 20s 752us/step - loss: 0.1069 - acc: 0.9653 - val_loss: 1.0274 - val_acc: 0.8269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb77548fd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model20 = model_spnet4()\n",
    "model20.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27200 samples, validate on 6800 samples\n",
      "Epoch 1/25\n",
      "27200/27200 [==============================] - 28s 1ms/step - loss: 3.1933 - acc: 0.2724 - val_loss: 1.7120 - val_acc: 0.4793\n",
      "Epoch 2/25\n",
      "27200/27200 [==============================] - 25s 910us/step - loss: 1.2499 - acc: 0.6100 - val_loss: 0.9231 - val_acc: 0.7093\n",
      "Epoch 3/25\n",
      "27200/27200 [==============================] - 26s 968us/step - loss: 0.8523 - acc: 0.7308 - val_loss: 0.8643 - val_acc: 0.7363\n",
      "Epoch 4/25\n",
      "27200/27200 [==============================] - 26s 948us/step - loss: 0.6947 - acc: 0.7804 - val_loss: 0.7010 - val_acc: 0.7875\n",
      "Epoch 5/25\n",
      "27200/27200 [==============================] - 24s 877us/step - loss: 0.5792 - acc: 0.8166 - val_loss: 0.7284 - val_acc: 0.7747\n",
      "Epoch 6/25\n",
      "27200/27200 [==============================] - 26s 939us/step - loss: 0.5058 - acc: 0.8380 - val_loss: 0.6085 - val_acc: 0.8113\n",
      "Epoch 7/25\n",
      "27200/27200 [==============================] - 24s 896us/step - loss: 0.4358 - acc: 0.8596 - val_loss: 0.6493 - val_acc: 0.8090\n",
      "Epoch 8/25\n",
      "27200/27200 [==============================] - 28s 1ms/step - loss: 0.3877 - acc: 0.8754 - val_loss: 0.6253 - val_acc: 0.8196\n",
      "Epoch 9/25\n",
      "27200/27200 [==============================] - 28s 1ms/step - loss: 0.3333 - acc: 0.8904 - val_loss: 0.7187 - val_acc: 0.8029\n",
      "Epoch 10/25\n",
      "27200/27200 [==============================] - 29s 1ms/step - loss: 0.3005 - acc: 0.9042 - val_loss: 0.6485 - val_acc: 0.8235\n",
      "Epoch 11/25\n",
      "27200/27200 [==============================] - 28s 1ms/step - loss: 0.2682 - acc: 0.9119 - val_loss: 0.6691 - val_acc: 0.8226\n",
      "Epoch 12/25\n",
      "27200/27200 [==============================] - 24s 895us/step - loss: 0.2375 - acc: 0.9194 - val_loss: 0.6621 - val_acc: 0.8284\n",
      "Epoch 13/25\n",
      "27200/27200 [==============================] - 26s 964us/step - loss: 0.2028 - acc: 0.9317 - val_loss: 0.7226 - val_acc: 0.8251\n",
      "Epoch 14/25\n",
      "27200/27200 [==============================] - 28s 1ms/step - loss: 0.2046 - acc: 0.9326 - val_loss: 0.7108 - val_acc: 0.8316\n",
      "Epoch 15/25\n",
      "27200/27200 [==============================] - 28s 1ms/step - loss: 0.1639 - acc: 0.9455 - val_loss: 0.7530 - val_acc: 0.8301\n",
      "Epoch 16/25\n",
      "27200/27200 [==============================] - 27s 989us/step - loss: 0.1595 - acc: 0.9488 - val_loss: 0.9203 - val_acc: 0.8176\n",
      "Epoch 17/25\n",
      "27200/27200 [==============================] - 28s 1ms/step - loss: 0.1337 - acc: 0.9549 - val_loss: 0.8389 - val_acc: 0.8296\n",
      "Epoch 18/25\n",
      "27200/27200 [==============================] - 26s 944us/step - loss: 0.1328 - acc: 0.9564 - val_loss: 0.8480 - val_acc: 0.8325\n",
      "Epoch 19/25\n",
      "27200/27200 [==============================] - 28s 1ms/step - loss: 0.1192 - acc: 0.9601 - val_loss: 0.9165 - val_acc: 0.8231\n",
      "Epoch 20/25\n",
      "27200/27200 [==============================] - 27s 1ms/step - loss: 0.1168 - acc: 0.9614 - val_loss: 0.8659 - val_acc: 0.8416\n",
      "Epoch 21/25\n",
      "27200/27200 [==============================] - 28s 1ms/step - loss: 0.1075 - acc: 0.9656 - val_loss: 0.9251 - val_acc: 0.8357\n",
      "Epoch 22/25\n",
      "27200/27200 [==============================] - 27s 1ms/step - loss: 0.0993 - acc: 0.9674 - val_loss: 0.9824 - val_acc: 0.8325\n",
      "Epoch 23/25\n",
      "27200/27200 [==============================] - 28s 1ms/step - loss: 0.1006 - acc: 0.9671 - val_loss: 1.0561 - val_acc: 0.8244\n",
      "Epoch 24/25\n",
      "27200/27200 [==============================] - 27s 983us/step - loss: 0.0900 - acc: 0.9709 - val_loss: 0.9623 - val_acc: 0.8371\n",
      "Epoch 25/25\n",
      "27200/27200 [==============================] - 27s 1ms/step - loss: 0.0827 - acc: 0.9725 - val_loss: 0.9926 - val_acc: 0.8381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4699efbf50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model26 = model_spnet4()\n",
    "model26.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_spnet6():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(20, kernel_size=(6, 6),strides=1, input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(ZeroPadding2D(padding=(2,2)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(ZeroPadding2D(padding=(2,2)))\n",
    "    model.add(Conv2D(50, kernel_size=(6, 6)))\n",
    "    model.add(ZeroPadding2D(padding=(2,2)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(ZeroPadding2D(padding=(2,2)))\n",
    "    model.add(Conv2D(50, kernel_size=(6, 6), strides=1))\n",
    "    model.add(ZeroPadding2D(padding=(2,2)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27200 samples, validate on 6800 samples\n",
      "Epoch 1/25\n",
      "27200/27200 [==============================] - 15s 559us/step - loss: 2.4705 - acc: 0.2908 - val_loss: 1.5043 - val_acc: 0.5247\n",
      "Epoch 2/25\n",
      "27200/27200 [==============================] - 15s 565us/step - loss: 1.3248 - acc: 0.5861 - val_loss: 1.5545 - val_acc: 0.5422\n",
      "Epoch 3/25\n",
      "27200/27200 [==============================] - 14s 513us/step - loss: 0.9625 - acc: 0.6969 - val_loss: 1.1109 - val_acc: 0.6628\n",
      "Epoch 4/25\n",
      "27200/27200 [==============================] - 15s 536us/step - loss: 0.7988 - acc: 0.7517 - val_loss: 1.1172 - val_acc: 0.6718\n",
      "Epoch 5/25\n",
      "27200/27200 [==============================] - 14s 501us/step - loss: 0.6904 - acc: 0.7810 - val_loss: 0.8413 - val_acc: 0.7451\n",
      "Epoch 6/25\n",
      "27200/27200 [==============================] - 14s 518us/step - loss: 0.6126 - acc: 0.8076 - val_loss: 0.7141 - val_acc: 0.7847\n",
      "Epoch 7/25\n",
      "27200/27200 [==============================] - 15s 534us/step - loss: 0.5604 - acc: 0.8253 - val_loss: 0.6384 - val_acc: 0.8084\n",
      "Epoch 8/25\n",
      "27200/27200 [==============================] - 14s 529us/step - loss: 0.5071 - acc: 0.8398 - val_loss: 0.7029 - val_acc: 0.7854\n",
      "Epoch 9/25\n",
      "27200/27200 [==============================] - 15s 569us/step - loss: 0.4664 - acc: 0.8517 - val_loss: 0.7242 - val_acc: 0.7801\n",
      "Epoch 10/25\n",
      "27200/27200 [==============================] - 14s 509us/step - loss: 0.4282 - acc: 0.8622 - val_loss: 0.7131 - val_acc: 0.7971\n",
      "Epoch 11/25\n",
      "27200/27200 [==============================] - 14s 531us/step - loss: 0.3916 - acc: 0.8735 - val_loss: 0.6568 - val_acc: 0.8188\n",
      "Epoch 12/25\n",
      "27200/27200 [==============================] - 15s 547us/step - loss: 0.3600 - acc: 0.8847 - val_loss: 0.6714 - val_acc: 0.8149\n",
      "Epoch 13/25\n",
      "27200/27200 [==============================] - 14s 524us/step - loss: 0.3344 - acc: 0.8894 - val_loss: 0.6965 - val_acc: 0.8157\n",
      "Epoch 14/25\n",
      "27200/27200 [==============================] - 14s 509us/step - loss: 0.3076 - acc: 0.8988 - val_loss: 0.6950 - val_acc: 0.8222\n",
      "Epoch 15/25\n",
      "27200/27200 [==============================] - 14s 522us/step - loss: 0.2883 - acc: 0.9068 - val_loss: 0.6997 - val_acc: 0.8172\n",
      "Epoch 16/25\n",
      "27200/27200 [==============================] - 15s 541us/step - loss: 0.2602 - acc: 0.9130 - val_loss: 0.7615 - val_acc: 0.8222\n",
      "Epoch 17/25\n",
      "27200/27200 [==============================] - 16s 600us/step - loss: 0.2511 - acc: 0.9185 - val_loss: 0.7131 - val_acc: 0.8272\n",
      "Epoch 18/25\n",
      "27200/27200 [==============================] - 15s 562us/step - loss: 0.2257 - acc: 0.9264 - val_loss: 0.8370 - val_acc: 0.8165\n",
      "Epoch 19/25\n",
      "27200/27200 [==============================] - 16s 591us/step - loss: 0.2182 - acc: 0.9280 - val_loss: 0.7685 - val_acc: 0.8182\n",
      "Epoch 20/25\n",
      "27200/27200 [==============================] - 14s 529us/step - loss: 0.2088 - acc: 0.9310 - val_loss: 0.7863 - val_acc: 0.8257\n",
      "Epoch 21/25\n",
      "27200/27200 [==============================] - 14s 522us/step - loss: 0.1804 - acc: 0.9393 - val_loss: 0.9446 - val_acc: 0.8063\n",
      "Epoch 22/25\n",
      "27200/27200 [==============================] - 14s 513us/step - loss: 0.1731 - acc: 0.9407 - val_loss: 0.8876 - val_acc: 0.8141\n",
      "Epoch 23/25\n",
      "27200/27200 [==============================] - 14s 522us/step - loss: 0.1590 - acc: 0.9471 - val_loss: 0.8309 - val_acc: 0.8346\n",
      "Epoch 24/25\n",
      "27200/27200 [==============================] - 14s 526us/step - loss: 0.1511 - acc: 0.9517 - val_loss: 0.8956 - val_acc: 0.8290\n",
      "Epoch 25/25\n",
      "27200/27200 [==============================] - 16s 588us/step - loss: 0.1373 - acc: 0.9540 - val_loss: 0.9362 - val_acc: 0.8210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feba2df6f10>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model13 = model_spnet6()\n",
    "model13.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27200 samples, validate on 6800 samples\n",
      "Epoch 1/25\n",
      "27200/27200 [==============================] - 23s 859us/step - loss: 2.3739 - acc: 0.2780 - val_loss: 1.8250 - val_acc: 0.4237\n",
      "Epoch 2/25\n",
      "27200/27200 [==============================] - 22s 811us/step - loss: 1.3013 - acc: 0.5892 - val_loss: 0.9460 - val_acc: 0.6999\n",
      "Epoch 3/25\n",
      "27200/27200 [==============================] - 28s 1ms/step - loss: 0.9265 - acc: 0.7094 - val_loss: 0.8411 - val_acc: 0.7371\n",
      "Epoch 4/25\n",
      "27200/27200 [==============================] - 26s 947us/step - loss: 0.7390 - acc: 0.7695 - val_loss: 0.7698 - val_acc: 0.7626\n",
      "Epoch 5/25\n",
      "27200/27200 [==============================] - 28s 1ms/step - loss: 0.6404 - acc: 0.7978 - val_loss: 0.8157 - val_acc: 0.7562\n",
      "Epoch 6/25\n",
      "27200/27200 [==============================] - 26s 960us/step - loss: 0.5624 - acc: 0.8230 - val_loss: 0.6342 - val_acc: 0.8054\n",
      "Epoch 7/25\n",
      "27200/27200 [==============================] - 28s 1ms/step - loss: 0.4995 - acc: 0.8381 - val_loss: 0.7484 - val_acc: 0.7813\n",
      "Epoch 8/25\n",
      "27200/27200 [==============================] - 28s 1ms/step - loss: 0.4379 - acc: 0.8605 - val_loss: 0.7291 - val_acc: 0.7925\n",
      "Epoch 9/25\n",
      "27200/27200 [==============================] - 24s 892us/step - loss: 0.4039 - acc: 0.8705 - val_loss: 0.8347 - val_acc: 0.7771\n",
      "Epoch 10/25\n",
      "27200/27200 [==============================] - 23s 842us/step - loss: 0.3525 - acc: 0.8851 - val_loss: 0.6972 - val_acc: 0.8016\n",
      "Epoch 11/25\n",
      "27200/27200 [==============================] - 23s 860us/step - loss: 0.3206 - acc: 0.8940 - val_loss: 0.6687 - val_acc: 0.8171\n",
      "Epoch 12/25\n",
      "27200/27200 [==============================] - 24s 894us/step - loss: 0.2909 - acc: 0.9052 - val_loss: 0.7027 - val_acc: 0.8247\n",
      "Epoch 13/25\n",
      "27200/27200 [==============================] - 25s 926us/step - loss: 0.2689 - acc: 0.9114 - val_loss: 0.8086 - val_acc: 0.8013\n",
      "Epoch 14/25\n",
      "27200/27200 [==============================] - 25s 908us/step - loss: 0.2405 - acc: 0.9207 - val_loss: 0.7779 - val_acc: 0.8137\n",
      "Epoch 15/25\n",
      "27200/27200 [==============================] - 26s 949us/step - loss: 0.2219 - acc: 0.9271 - val_loss: 0.7553 - val_acc: 0.8265\n",
      "Epoch 16/25\n",
      "27200/27200 [==============================] - 24s 877us/step - loss: 0.2018 - acc: 0.9339 - val_loss: 0.8741 - val_acc: 0.8085\n",
      "Epoch 17/25\n",
      "27200/27200 [==============================] - 22s 824us/step - loss: 0.1780 - acc: 0.9426 - val_loss: 0.7672 - val_acc: 0.8332\n",
      "Epoch 18/25\n",
      "27200/27200 [==============================] - 25s 915us/step - loss: 0.1692 - acc: 0.9440 - val_loss: 0.8312 - val_acc: 0.8281\n",
      "Epoch 19/25\n",
      "27200/27200 [==============================] - 25s 908us/step - loss: 0.1627 - acc: 0.9462 - val_loss: 0.9044 - val_acc: 0.8174\n",
      "Epoch 20/25\n",
      "27200/27200 [==============================] - 24s 886us/step - loss: 0.1508 - acc: 0.9508 - val_loss: 0.9862 - val_acc: 0.8143\n",
      "Epoch 21/25\n",
      "27200/27200 [==============================] - 24s 873us/step - loss: 0.1450 - acc: 0.9528 - val_loss: 1.0720 - val_acc: 0.8053\n",
      "Epoch 22/25\n",
      "27200/27200 [==============================] - 20s 747us/step - loss: 0.1406 - acc: 0.9557 - val_loss: 0.9052 - val_acc: 0.8412\n",
      "Epoch 23/25\n",
      "27200/27200 [==============================] - 20s 738us/step - loss: 0.1148 - acc: 0.9637 - val_loss: 1.0473 - val_acc: 0.8284\n",
      "Epoch 24/25\n",
      "27200/27200 [==============================] - 21s 757us/step - loss: 0.1231 - acc: 0.9607 - val_loss: 1.0045 - val_acc: 0.8260\n",
      "Epoch 25/25\n",
      "27200/27200 [==============================] - 20s 736us/step - loss: 0.1182 - acc: 0.9638 - val_loss: 0.9630 - val_acc: 0.8296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb728c4fd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model20 = model_spnet6()\n",
    "model20.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27200 samples, validate on 6800 samples\n",
      "Epoch 1/25\n",
      "27200/27200 [==============================] - 31s 1ms/step - loss: 2.4172 - acc: 0.2698 - val_loss: 1.5337 - val_acc: 0.4985\n",
      "Epoch 2/25\n",
      "27200/27200 [==============================] - 31s 1ms/step - loss: 1.3346 - acc: 0.5718 - val_loss: 1.1521 - val_acc: 0.6291\n",
      "Epoch 3/25\n",
      "27200/27200 [==============================] - 31s 1ms/step - loss: 0.9560 - acc: 0.6988 - val_loss: 0.8599 - val_acc: 0.7259\n",
      "Epoch 4/25\n",
      "27200/27200 [==============================] - 31s 1ms/step - loss: 0.7378 - acc: 0.7643 - val_loss: 0.7917 - val_acc: 0.7535\n",
      "Epoch 5/25\n",
      "27200/27200 [==============================] - 32s 1ms/step - loss: 0.6457 - acc: 0.7951 - val_loss: 0.8254 - val_acc: 0.7572\n",
      "Epoch 6/25\n",
      "27200/27200 [==============================] - 38s 1ms/step - loss: 0.5635 - acc: 0.8214 - val_loss: 0.7040 - val_acc: 0.7869\n",
      "Epoch 7/25\n",
      "27200/27200 [==============================] - 39s 1ms/step - loss: 0.5057 - acc: 0.8398 - val_loss: 0.5954 - val_acc: 0.8231\n",
      "Epoch 8/25\n",
      "27200/27200 [==============================] - 37s 1ms/step - loss: 0.4448 - acc: 0.8563 - val_loss: 0.6635 - val_acc: 0.8109\n",
      "Epoch 9/25\n",
      "27200/27200 [==============================] - 39s 1ms/step - loss: 0.3926 - acc: 0.8737 - val_loss: 1.0151 - val_acc: 0.7543\n",
      "Epoch 10/25\n",
      "27200/27200 [==============================] - 34s 1ms/step - loss: 0.3602 - acc: 0.8846 - val_loss: 0.7055 - val_acc: 0.8029\n",
      "Epoch 11/25\n",
      "27200/27200 [==============================] - 31s 1ms/step - loss: 0.3141 - acc: 0.8974 - val_loss: 0.6656 - val_acc: 0.8231\n",
      "Epoch 12/25\n",
      "27200/27200 [==============================] - 37s 1ms/step - loss: 0.2992 - acc: 0.9044 - val_loss: 0.6783 - val_acc: 0.8190\n",
      "Epoch 13/25\n",
      "27200/27200 [==============================] - 33s 1ms/step - loss: 0.2530 - acc: 0.9175 - val_loss: 0.8017 - val_acc: 0.8169\n",
      "Epoch 14/25\n",
      "27200/27200 [==============================] - 33s 1ms/step - loss: 0.2435 - acc: 0.9199 - val_loss: 0.6852 - val_acc: 0.8296\n",
      "Epoch 15/25\n",
      "27200/27200 [==============================] - 33s 1ms/step - loss: 0.2152 - acc: 0.9292 - val_loss: 0.7679 - val_acc: 0.8275\n",
      "Epoch 16/25\n",
      "27200/27200 [==============================] - 33s 1ms/step - loss: 0.2000 - acc: 0.9346 - val_loss: 0.9645 - val_acc: 0.8100\n",
      "Epoch 17/25\n",
      "27200/27200 [==============================] - 31s 1ms/step - loss: 0.1789 - acc: 0.9419 - val_loss: 0.7326 - val_acc: 0.8332\n",
      "Epoch 18/25\n",
      "27200/27200 [==============================] - 33s 1ms/step - loss: 0.1715 - acc: 0.9456 - val_loss: 0.8595 - val_acc: 0.8149\n",
      "Epoch 19/25\n",
      "27200/27200 [==============================] - 31s 1ms/step - loss: 0.1441 - acc: 0.9530 - val_loss: 0.9682 - val_acc: 0.8085\n",
      "Epoch 20/25\n",
      "27200/27200 [==============================] - 36s 1ms/step - loss: 0.1506 - acc: 0.9527 - val_loss: 0.8587 - val_acc: 0.8365\n",
      "Epoch 21/25\n",
      "27200/27200 [==============================] - 31s 1ms/step - loss: 0.1250 - acc: 0.9607 - val_loss: 0.9876 - val_acc: 0.8301\n",
      "Epoch 22/25\n",
      "27200/27200 [==============================] - 31s 1ms/step - loss: 0.1215 - acc: 0.9617 - val_loss: 0.9671 - val_acc: 0.8275\n",
      "Epoch 23/25\n",
      "27200/27200 [==============================] - 34s 1ms/step - loss: 0.1131 - acc: 0.9638 - val_loss: 1.0577 - val_acc: 0.8281\n",
      "Epoch 24/25\n",
      "27200/27200 [==============================] - 34s 1ms/step - loss: 0.1142 - acc: 0.9647 - val_loss: 1.0713 - val_acc: 0.8276\n",
      "Epoch 25/25\n",
      "27200/27200 [==============================] - 34s 1ms/step - loss: 0.1094 - acc: 0.9656 - val_loss: 1.0440 - val_acc: 0.8316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f46953bcf10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model26 = model_spnet6()\n",
    "model26.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spnet13 = {}\n",
    "lenet13 = {}\n",
    "spnet13_k2 = {}\n",
    "spnet13_k3 = {}\n",
    "spnet13_k4 = {}\n",
    "spnet13_k6 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spnet13[1] = 0.2648; spnet13[5] = 0.7553; spnet13[10] = 0.8269; spnet13[15] = 0.8600; spnet13[20] = 0.8843; spnet13[25] = 0.9051; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lenet13[1] = 0.4376; lenet13[5] = 0.8274; lenet13[10] = 0.9156; lenet13[15] = 0.9586; lenet13[20] = 0.9785; lenet13[25] = 0.9851; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spnet13_k2[1] = 0.1771; spnet13_k2[5] = 0.5764; spnet13_k2[10] = 0.6819; spnet13_k2[15] = 0.7377; spnet13_k2[20] = 0.7696; spnet13_k2[25] = 0.7943; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spnet13_k3[1] = 0.2563; spnet13_k3[5] = 0.7487; spnet13_k3[10] = 0.8386; spnet13_k3[15] = 0.8800; spnet13_k3[20] = 0.9139; spnet13_k3[25] = 0.9364; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spnet13_k4[1] = 0.3001; spnet13_k4[5] = 0.7926; spnet13_k4[10] = 0.8725; spnet13_k4[15] = 0.9236; spnet13_k4[20] = 0.9450; spnet13_k4[25] = 0.9602; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spnet13_k6[1] = 0.2908; spnet13_k6[5] = 0.7810; spnet13_k6[10] = 0.8622; spnet13_k6[15] = 0.9068; spnet13_k6[20] = 0.9310; spnet13_k6[25] = 0.9540; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tabel_acc13 = pd.DataFrame([spnet13.keys(),spnet13.values(),lenet13.values(),spnet13_k2.values(),spnet13_k3.values(),spnet13_k4.values(),spnet13_k6.values()])\n",
    "tabel_acc13 = tabel_acc13.T\n",
    "tabel_acc13.columns = ['number of epoch','SPNet','Lenet','SPnet k=2x2','SPnet k=3x3','SPnet k=4x4','SPnet k=6x6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL ACCURATION FOR COEFFICIENT 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of epoch</th>\n",
       "      <th>SPNet</th>\n",
       "      <th>Lenet</th>\n",
       "      <th>SPnet k=2x2</th>\n",
       "      <th>SPnet k=3x3</th>\n",
       "      <th>SPnet k=4x4</th>\n",
       "      <th>SPnet k=6x6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2648</td>\n",
       "      <td>0.4376</td>\n",
       "      <td>0.1771</td>\n",
       "      <td>0.2563</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.2908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.7553</td>\n",
       "      <td>0.8274</td>\n",
       "      <td>0.5764</td>\n",
       "      <td>0.7487</td>\n",
       "      <td>0.7926</td>\n",
       "      <td>0.7810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.8269</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.6819</td>\n",
       "      <td>0.8386</td>\n",
       "      <td>0.8725</td>\n",
       "      <td>0.8622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.9586</td>\n",
       "      <td>0.7377</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.9236</td>\n",
       "      <td>0.9068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.8843</td>\n",
       "      <td>0.9785</td>\n",
       "      <td>0.7696</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.9450</td>\n",
       "      <td>0.9310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.9051</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.7943</td>\n",
       "      <td>0.9364</td>\n",
       "      <td>0.9602</td>\n",
       "      <td>0.9540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number of epoch   SPNet   Lenet  SPnet k=2x2  SPnet k=3x3  SPnet k=4x4  \\\n",
       "0              1.0  0.2648  0.4376       0.1771       0.2563       0.3001   \n",
       "1              5.0  0.7553  0.8274       0.5764       0.7487       0.7926   \n",
       "2             10.0  0.8269  0.9156       0.6819       0.8386       0.8725   \n",
       "3             15.0  0.8600  0.9586       0.7377       0.8800       0.9236   \n",
       "4             20.0  0.8843  0.9785       0.7696       0.9139       0.9450   \n",
       "5             25.0  0.9051  0.9851       0.7943       0.9364       0.9602   \n",
       "\n",
       "   SPnet k=6x6  \n",
       "0       0.2908  \n",
       "1       0.7810  \n",
       "2       0.8622  \n",
       "3       0.9068  \n",
       "4       0.9310  \n",
       "5       0.9540  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabel_acc13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tabel_acc13_val = pd.DataFrame([0.8300,0.8169,0.7909,0.8375,0.8362,0.8346])\n",
    "tabel_acc13_val = tabel_acc13_val.T\n",
    "tabel_acc13_val.columns = ['SPNet','Lenet','Lenet k=2x2','Lenet k=3x3','Lenet k=4x4','Lenet k=6x6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VALIDATION ACCURATION FOR COEFFICIENT 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPNet</th>\n",
       "      <th>Lenet</th>\n",
       "      <th>Lenet k=2x2</th>\n",
       "      <th>Lenet k=3x3</th>\n",
       "      <th>Lenet k=4x4</th>\n",
       "      <th>Lenet k=6x6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.8169</td>\n",
       "      <td>0.7909</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.8362</td>\n",
       "      <td>0.8346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SPNet   Lenet  Lenet k=2x2  Lenet k=3x3  Lenet k=4x4  Lenet k=6x6\n",
       "0   0.83  0.8169       0.7909       0.8375       0.8362       0.8346"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabel_acc13_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spnet = {}\n",
    "lenet = {}\n",
    "spnet_k2 = {}\n",
    "spnet_k3 = {}\n",
    "spnet_k4 = {}\n",
    "spnet_k6 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spnet[1] = 0.2845; spnet[5] = 0.7864; spnet[10] = 0.8581; spnet[15] = 0.8993; spnet[20] = 0.9284; spnet[25] = 0.9472; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lenet[1] = 0.4487; lenet[5] = 0.8644; lenet[10] = 0.9549; lenet[15] = 0.9792; lenet[20] = 0.9885; lenet[25] = 0.9882; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spnet_k2[1] = 0.1978; spnet_k2[5] = 0.6253; spnet_k2[10] = 0.7306; spnet_k2[15] = 0.7838; spnet_k2[20] = 0.8112; spnet_k2[25] = 0.8468; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spnet_k3[1] = 0.2657; spnet_k3[5] = 0.7471; spnet_k3[10] = 0.8416; spnet_k3[15] = 0.8951; spnet_k3[20] = 0.9296; spnet_k3[25] = 0.9528; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spnet_k4[1] = 0.2628; spnet_k4[5] = 0.8108; spnet_k4[10] = 0.8961; spnet_k4[15] = 0.9350; spnet_k4[20] = 0.9598; spnet_k4[25] = 0.9653; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spnet_k6[1] = 0.2780; spnet_k6[5] = 0.7978; spnet_k6[10] = 0.8851; spnet_k6[15] = 0.9271; spnet_k6[20] = 0.9508; spnet_k6[25] = 0.9638; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tabel_acc20 = pd.DataFrame([spnet.keys(),spnet.values(),lenet.values(),spnet_k2.values(),spnet_k3.values(),spnet_k4.values(),spnet_k6.values()])\n",
    "tabel_acc20 = tabel_acc20.T\n",
    "tabel_acc20.columns = ['number of epoch','SPNet','Lenet','SPnet k=2x2','SPnet k=3x3','SPnet k=4x4','SPnet k=6x6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL ACCURATION FOR KOEFISIEN 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of epoch</th>\n",
       "      <th>SPNet</th>\n",
       "      <th>Lenet</th>\n",
       "      <th>SPnet k=2x2</th>\n",
       "      <th>SPnet k=3x3</th>\n",
       "      <th>SPnet k=4x4</th>\n",
       "      <th>SPnet k=6x6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2845</td>\n",
       "      <td>0.4487</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.2657</td>\n",
       "      <td>0.2628</td>\n",
       "      <td>0.2780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.7864</td>\n",
       "      <td>0.8644</td>\n",
       "      <td>0.6253</td>\n",
       "      <td>0.7471</td>\n",
       "      <td>0.8108</td>\n",
       "      <td>0.7978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.8581</td>\n",
       "      <td>0.9549</td>\n",
       "      <td>0.7306</td>\n",
       "      <td>0.8416</td>\n",
       "      <td>0.8961</td>\n",
       "      <td>0.8851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>0.9792</td>\n",
       "      <td>0.7838</td>\n",
       "      <td>0.8951</td>\n",
       "      <td>0.9350</td>\n",
       "      <td>0.9271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.9284</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.8112</td>\n",
       "      <td>0.9296</td>\n",
       "      <td>0.9598</td>\n",
       "      <td>0.9508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.9472</td>\n",
       "      <td>0.9882</td>\n",
       "      <td>0.8468</td>\n",
       "      <td>0.9528</td>\n",
       "      <td>0.9653</td>\n",
       "      <td>0.9638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number of epoch   SPNet   Lenet  SPnet k=2x2  SPnet k=3x3  SPnet k=4x4  \\\n",
       "0              1.0  0.2845  0.4487       0.1978       0.2657       0.2628   \n",
       "1              5.0  0.7864  0.8644       0.6253       0.7471       0.8108   \n",
       "2             10.0  0.8581  0.9549       0.7306       0.8416       0.8961   \n",
       "3             15.0  0.8993  0.9792       0.7838       0.8951       0.9350   \n",
       "4             20.0  0.9284  0.9885       0.8112       0.9296       0.9598   \n",
       "5             25.0  0.9472  0.9882       0.8468       0.9528       0.9653   \n",
       "\n",
       "   SPnet k=6x6  \n",
       "0       0.2780  \n",
       "1       0.7978  \n",
       "2       0.8851  \n",
       "3       0.9271  \n",
       "4       0.9508  \n",
       "5       0.9638  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabel_acc20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tabel_acc20_val = pd.DataFrame([0.8213,0.8200,0.8015,0.8096,0.8416,0.8362])\n",
    "tabel_acc20_val = tabel_acc20_val.T\n",
    "tabel_acc20_val.columns = ['SPNet','Lenet','Lenet k=2x2','Lenet k=3x3','Lenet k=4x4','Lenet k=6x6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VALIDATION ACCURATION FOR COEFFICIENT 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPNet</th>\n",
       "      <th>Lenet</th>\n",
       "      <th>Lenet k=2x2</th>\n",
       "      <th>Lenet k=3x3</th>\n",
       "      <th>Lenet k=4x4</th>\n",
       "      <th>Lenet k=6x6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8213</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.8015</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>0.8416</td>\n",
       "      <td>0.8362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SPNet  Lenet  Lenet k=2x2  Lenet k=3x3  Lenet k=4x4  Lenet k=6x6\n",
       "0  0.8213   0.82       0.8015       0.8096       0.8416       0.8362"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabel_acc20_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spnet26 = {}\n",
    "lenet26 = {}\n",
    "spnet26_k2 = {}\n",
    "spnet26_k3 = {}\n",
    "spnet26_k4 = {}\n",
    "spnet26_k6 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spnet26[1] = 0.2635; spnet26[5] = 0.7775; spnet26[10] = 0.8577; spnet26[15] = 0.8991; spnet26[20] = 0.9262; spnet26[25] = 0.9459; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lenet26[1] = 0.4579; lenet26[5] = 0.8712; lenet26[10] = 0.9612; lenet26[15] = 0.9831; lenet26[20] = 0.9881; lenet26[25] = 0.9896;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spnet26_k2[1] = 0.2125; spnet26_k2[5] = 0.6430; spnet26_k2[10] = 0.7509; spnet26_k2[15] = 0.8048; spnet26_k2[20] = 0.8412; spnet26_k2[25] = 0.8742; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spnet26_k3[1] = 0.1829; spnet26_k3[5] = 0.7401; spnet26_k3[10] = 0.8497; spnet26_k3[15] = 0.9056; spnet26_k3[20] = 0.9400; spnet26_k3[25] = 0.9626; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spnet26_k4[1] = 0.2724; spnet26_k4[5] = 0.8166; spnet26_k4[10] = 0.9042; spnet26_k4[15] = 0.9455; spnet26_k4[20] = 0.9614; spnet26_k4[25] = 0.9725; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spnet26_k6[1] = 0.2698; spnet26_k6[5] = 0.7951; spnet26_k6[10] = 0.8846; spnet26_k6[15] = 0.9292; spnet26_k6[20] = 0.9527; spnet26_k6[25] = 0.9656; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tabel_acc26 = pd.DataFrame([spnet26.keys(),spnet26.values(),lenet26.values(),spnet26_k2.values(),spnet26_k3.values(),spnet26_k4.values(),spnet26_k6.values()])\n",
    "tabel_acc26 = tabel_acc26.T\n",
    "tabel_acc26.columns = ['number of epoch','SPNet','Lenet','SPnet k=2x2','SPnet k=3x3','SPnet k=4x4','SPnet k=6x6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL ACCURATION FOR COEFFICIENT 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of epoch</th>\n",
       "      <th>SPNet</th>\n",
       "      <th>Lenet</th>\n",
       "      <th>SPnet k=2x2</th>\n",
       "      <th>SPnet k=3x3</th>\n",
       "      <th>SPnet k=4x4</th>\n",
       "      <th>SPnet k=6x6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2635</td>\n",
       "      <td>0.4579</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1829</td>\n",
       "      <td>0.2724</td>\n",
       "      <td>0.2698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.7775</td>\n",
       "      <td>0.8712</td>\n",
       "      <td>0.6430</td>\n",
       "      <td>0.7401</td>\n",
       "      <td>0.8166</td>\n",
       "      <td>0.7951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.8577</td>\n",
       "      <td>0.9612</td>\n",
       "      <td>0.7509</td>\n",
       "      <td>0.8497</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.8846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.8991</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>0.8048</td>\n",
       "      <td>0.9056</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.9292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>0.9881</td>\n",
       "      <td>0.8412</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9614</td>\n",
       "      <td>0.9527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>0.8742</td>\n",
       "      <td>0.9626</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.9656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number of epoch   SPNet   Lenet  SPnet k=2x2  SPnet k=3x3  SPnet k=4x4  \\\n",
       "0              1.0  0.2635  0.4579       0.2125       0.1829       0.2724   \n",
       "1              5.0  0.7775  0.8712       0.6430       0.7401       0.8166   \n",
       "2             10.0  0.8577  0.9612       0.7509       0.8497       0.9042   \n",
       "3             15.0  0.8991  0.9831       0.8048       0.9056       0.9455   \n",
       "4             20.0  0.9262  0.9881       0.8412       0.9400       0.9614   \n",
       "5             25.0  0.9459  0.9896       0.8742       0.9626       0.9725   \n",
       "\n",
       "   SPnet k=6x6  \n",
       "0       0.2698  \n",
       "1       0.7951  \n",
       "2       0.8846  \n",
       "3       0.9292  \n",
       "4       0.9527  \n",
       "5       0.9656  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabel_acc26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tabel_acc26_val = pd.DataFrame([0.8229,0.8251,0.7976,0.8019,0.8493,0.8431])\n",
    "tabel_acc26_val = tabel_acc26_val.T\n",
    "tabel_acc26_val.columns = ['SPNet','Lenet','Lenet k=2x2','Lenet k=3x3','Lenet k=4x4','Lenet k=6x6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VALIDATION ACCURATION FOR COEFFICIENT 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPNet</th>\n",
       "      <th>Lenet</th>\n",
       "      <th>Lenet k=2x2</th>\n",
       "      <th>Lenet k=3x3</th>\n",
       "      <th>Lenet k=4x4</th>\n",
       "      <th>Lenet k=6x6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8229</td>\n",
       "      <td>0.8251</td>\n",
       "      <td>0.7976</td>\n",
       "      <td>0.8019</td>\n",
       "      <td>0.8493</td>\n",
       "      <td>0.8431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SPNet   Lenet  Lenet k=2x2  Lenet k=3x3  Lenet k=4x4  Lenet k=6x6\n",
       "0  0.8229  0.8251       0.7976       0.8019       0.8493       0.8431"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabel_acc26_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_graph = {}\n",
    "lenet_graph = {}\n",
    "spnet2_graph = {}\n",
    "spnet3_graph = {}\n",
    "spnet4_graph = {}\n",
    "spnet6_graph = {}\n",
    "sp_graph[13] = 0.83; lenet_graph[13] = 0.8169; spnet2_graph[13] = 0.7909; spnet3_graph[13] = 0.8375; spnet4_graph[13] = 0.8362; spnet6_graph[13] = 0.8346;\n",
    "sp_graph[20] = 0.8213; lenet_graph[20] = 0.82; spnet2_graph[20] = 0.8015; spnet3_graph[20] = 0.8096; spnet4_graph[20] = 0.8416; spnet6_graph[20] = 0.8362;\n",
    "sp_graph[26] = 0.8229; lenet_graph[26] = 0.8251; spnet2_graph[26] = 0.7976; spnet3_graph[26] = 0.8019; spnet4_graph[26] = 0.8493; spnet6_graph[26] = 0.8431;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAFkCAYAAABW9YMrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyARAkqQeMgGQJKmHTAAkSeqh/wf1WJVReu+SAQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4699e7ce90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sp = [sp_graph[26],sp_graph[20],sp_graph[13],0,0]\n",
    "le = [lenet_graph[26],lenet_graph[20],lenet_graph[13],0,0]\n",
    "sp2 = [spnet2_graph[26],spnet2_graph[20],spnet2_graph[13],0,0]\n",
    "sp3 = [spnet3_graph[26],spnet3_graph[20],spnet3_graph[13],0,0]\n",
    "sp4 = [spnet4_graph[26],spnet4_graph[20],spnet4_graph[13],0,0]\n",
    "sp6 = [spnet6_graph[26],spnet6_graph[20],spnet6_graph[13],0,0]\n",
    "index = [\"Koefisien 26\",'Koefisien 20','Koefisien 13','','']\n",
    "df = pd.DataFrame({'SPNet': sp,'Lenet': le,'Lenet 2x2': sp2,'SPnet3x3': sp3,'SPnet4x4': sp4,'SPnet6x6': sp6}, index=index)\n",
    "ax = df.plot.bar(rot=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tp = {}\n",
    "fp = {}\n",
    "fn = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in labels:\n",
    "    tp[i] = 0\n",
    "    fp[i] = 0\n",
    "    fn[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(0,6800):\n",
    "    sample = X_test[i].reshape(1, feature_dim_1, feature_dim_2, channel)\n",
    "    prediction = get_labels()[0][np.argmax(model20.predict(sample))]\n",
    "    real = get_labels()[0][np.argmax(y_test_hot[i])]\n",
    "    if (real == prediction):\n",
    "        count+=1\n",
    "        tp[real]+=1\n",
    "    else:\n",
    "        fn[prediction]+=1\n",
    "        fp[real]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision = {}\n",
    "recall = {}\n",
    "f1 = {}\n",
    "accurationn = {}\n",
    "error_rate = {}\n",
    "for i in labels:\n",
    "    precision[i] = 0\n",
    "    recall[i] = 0\n",
    "    f1[i] = 0\n",
    "    error_rate[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "for i in labels:\n",
    "    precision[i] = tp[i]/(tp[i]+fp[i])\n",
    "    recall[i] = tp[i]/(tp[i]+fn[i])\n",
    "    f1[i] = 2*(precision[i]*recall[i])/(precision[i]+recall[i])\n",
    "    error_rate[i] = 1-precision[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tabel_acc26_val = pd.DataFrame([precision.keys(),precision.values(),recall.values(),f1.values(),error_rate.values()])\n",
    "tabel_acc26_val = tabel_acc26_val.T\n",
    "tabel_acc26_val.columns = ['Label', 'Precision / Accuration', 'Recall', 'F - Measure','Error Rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Precision / Accuration</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F - Measure</th>\n",
       "      <th>Error Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sheila</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.848837</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>0.0875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seven</td>\n",
       "      <td>0.751534</td>\n",
       "      <td>0.847751</td>\n",
       "      <td>0.796748</td>\n",
       "      <td>0.248466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>right</td>\n",
       "      <td>0.810398</td>\n",
       "      <td>0.777126</td>\n",
       "      <td>0.793413</td>\n",
       "      <td>0.189602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>three</td>\n",
       "      <td>0.907514</td>\n",
       "      <td>0.850949</td>\n",
       "      <td>0.878322</td>\n",
       "      <td>0.0924855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.841642</td>\n",
       "      <td>0.827089</td>\n",
       "      <td>0.186969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>marvin</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.901198</td>\n",
       "      <td>0.898507</td>\n",
       "      <td>0.104167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wow</td>\n",
       "      <td>0.926346</td>\n",
       "      <td>0.786058</td>\n",
       "      <td>0.850455</td>\n",
       "      <td>0.0736544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>six</td>\n",
       "      <td>0.864706</td>\n",
       "      <td>0.854651</td>\n",
       "      <td>0.859649</td>\n",
       "      <td>0.135294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stop</td>\n",
       "      <td>0.815013</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.811749</td>\n",
       "      <td>0.184987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>up</td>\n",
       "      <td>0.753754</td>\n",
       "      <td>0.814935</td>\n",
       "      <td>0.783151</td>\n",
       "      <td>0.246246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bed</td>\n",
       "      <td>0.80112</td>\n",
       "      <td>0.752632</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.19888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dog</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.912752</td>\n",
       "      <td>0.816817</td>\n",
       "      <td>0.26087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>zero</td>\n",
       "      <td>0.82235</td>\n",
       "      <td>0.834302</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.17765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cat</td>\n",
       "      <td>0.850153</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>0.788652</td>\n",
       "      <td>0.149847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nine</td>\n",
       "      <td>0.738636</td>\n",
       "      <td>0.875421</td>\n",
       "      <td>0.801233</td>\n",
       "      <td>0.261364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>two</td>\n",
       "      <td>0.823344</td>\n",
       "      <td>0.765396</td>\n",
       "      <td>0.793313</td>\n",
       "      <td>0.176656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>house</td>\n",
       "      <td>0.888554</td>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.861314</td>\n",
       "      <td>0.111446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>yes</td>\n",
       "      <td>0.842262</td>\n",
       "      <td>0.862805</td>\n",
       "      <td>0.85241</td>\n",
       "      <td>0.157738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>left</td>\n",
       "      <td>0.716049</td>\n",
       "      <td>0.868914</td>\n",
       "      <td>0.78511</td>\n",
       "      <td>0.283951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.927492</td>\n",
       "      <td>0.872159</td>\n",
       "      <td>0.898975</td>\n",
       "      <td>0.0725076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label Precision / Accuration    Recall F - Measure Error Rate\n",
       "0   sheila                 0.9125  0.848837    0.879518     0.0875\n",
       "1    seven               0.751534  0.847751    0.796748   0.248466\n",
       "2    right               0.810398  0.777126    0.793413   0.189602\n",
       "3    three               0.907514  0.850949    0.878322  0.0924855\n",
       "4       no               0.813031  0.841642    0.827089   0.186969\n",
       "5   marvin               0.895833  0.901198    0.898507   0.104167\n",
       "6      wow               0.926346  0.786058    0.850455  0.0736544\n",
       "7      six               0.864706  0.854651    0.859649   0.135294\n",
       "8     stop               0.815013  0.808511    0.811749   0.184987\n",
       "9       up               0.753754  0.814935    0.783151   0.246246\n",
       "10     bed                0.80112  0.752632    0.776119    0.19888\n",
       "11     dog                0.73913  0.912752    0.816817    0.26087\n",
       "12    zero                0.82235  0.834302    0.828283    0.17765\n",
       "13     cat               0.850153   0.73545    0.788652   0.149847\n",
       "14    nine               0.738636  0.875421    0.801233   0.261364\n",
       "15     two               0.823344  0.765396    0.793313   0.176656\n",
       "16   house               0.888554  0.835694    0.861314   0.111446\n",
       "17     yes               0.842262  0.862805     0.85241   0.157738\n",
       "18    left               0.716049  0.868914     0.78511   0.283951\n",
       "19   happy               0.927492  0.872159    0.898975  0.0725076"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabel_acc26_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "print(predict('/home/daniel/datatest/dogg.wav', model=model20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
