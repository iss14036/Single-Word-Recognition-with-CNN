{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/daniel/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input: Folder Path\n",
    "# Output: Tuple (Label, Indices of the labels, one-hot encoded labels)\n",
    "def get_labels(path=DATA_PATH):\n",
    "    labels = os.listdir(path)\n",
    "    label_indices = np.arange(0, len(labels))\n",
    "    return labels, label_indices, to_categorical(label_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "DATA_PATH = \"/home/daniel/data/\"\n",
    "\n",
    "# Input: Folder Path\n",
    "# Output: Tuple (Label, Indices of the labels, one-hot encoded labels)\n",
    "def get_labels(path=DATA_PATH):\n",
    "    labels = os.listdir(path)\n",
    "    label_indices = np.arange(0, len(labels))\n",
    "    return labels, label_indices, to_categorical(label_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['marvin',\n",
       " 'happy',\n",
       " 'six',\n",
       " 'up',\n",
       " 'stop',\n",
       " 'yes',\n",
       " 'sheila',\n",
       " 'zero',\n",
       " 'dog',\n",
       " 'right',\n",
       " 'house',\n",
       " 'no',\n",
       " 'two',\n",
       " 'left',\n",
       " 'cat',\n",
       " 'nine',\n",
       " 'seven',\n",
       " 'three',\n",
       " 'wow',\n",
       " 'bed']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, _, _ = get_labels(DATA_PATH)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Handy function to convert wav2mfcc\n",
    "def wav2mfcc(file_path, max_len=11):\n",
    "    wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
    "    wave = wave[::3]\n",
    "    mfcc = librosa.feature.mfcc(wave, sr=16000)\n",
    "\n",
    "    # If maximum length exceeds mfcc lengths then pad the remaining ones\n",
    "    if (max_len > mfcc.shape[1]):\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "    # Else cutoff the remaining parts\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "    \n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_data_to_array(path=DATA_PATH, max_len=11):\n",
    "    labels, _, _ = get_labels(path)\n",
    "\n",
    "    for label in labels:\n",
    "        # Init mfcc vectors\n",
    "        mfcc_vectors = []\n",
    "\n",
    "        wavfiles = [path + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
    "        for wavfile in wavfiles:\n",
    "            mfcc = wav2mfcc(wavfile, max_len=max_len)\n",
    "            mfcc_vectors.append(mfcc)\n",
    "        np.save(label + '.npy', mfcc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_test(split_ratio=0.6, random_state=42):\n",
    "    # Get available labels\n",
    "    labels, indices, _ = get_labels(DATA_PATH)\n",
    "\n",
    "    # Getting first arrays\n",
    "    X = np.load(labels[0] + '.npy')\n",
    "    y = np.zeros(X.shape[0])\n",
    "\n",
    "    # Append all of the dataset into one single array, same goes for y\n",
    "    for i, label in enumerate(labels[1:]):\n",
    "        x = np.load(label + '.npy')\n",
    "        X = np.vstack((X, x))\n",
    "        y = np.append(y, np.full(x.shape[0], fill_value= (i + 1)))\n",
    "        print label\n",
    "    assert X.shape[0] == len(y)\n",
    "\n",
    "    return train_test_split(X, y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(path=DATA_PATH):\n",
    "    labels, _, _ = get_labels(path)\n",
    "    data = {}\n",
    "    for label in labels:\n",
    "        data[label] = {}\n",
    "        data[label]['path'] = [path  + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
    "\n",
    "        vectors = []\n",
    "\n",
    "        for wavfile in data[label]['path']:\n",
    "            wave, sr = librosa.load(wavfile, mono=True, sr=None)\n",
    "            # Downsampling\n",
    "            wave = wave[::3]\n",
    "            mfcc = librosa.feature.mfcc(wave, sr=16000)\n",
    "            vectors.append(mfcc)\n",
    "\n",
    "        data[label]['mfcc'] = vectors\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(path=DATA_PATH):\n",
    "    data = prepare_dataset(path)\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    for key in data:\n",
    "        for mfcc in data[key]['mfcc']:\n",
    "            dataset.append((key, mfcc))\n",
    "\n",
    "    return dataset[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy\n",
      "six\n",
      "up\n",
      "stop\n",
      "yes\n",
      "sheila\n",
      "zero\n",
      "dog\n",
      "right\n",
      "house\n",
      "no\n",
      "two\n",
      "left\n",
      "cat\n",
      "nine\n",
      "seven\n",
      "three\n",
      "wow\n",
      "bed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D,Conv1D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Second dimension of the feature is dim2\n",
    "feature_dim_2 = 11\n",
    "\n",
    "# Save data to array file first\n",
    "save_data_to_array(max_len=feature_dim_2)\n",
    "\n",
    "# # Loading train set and test set\n",
    "X_train, X_test, y_train, y_test = get_train_test()\n",
    "\n",
    "# # Feature dimension\n",
    "feature_dim_1 = 20\n",
    "channel = 1\n",
    "epochs = 50\n",
    "batch_size = 100\n",
    "verbose = 1\n",
    "num_classes = 20\n",
    "\n",
    "# Reshaping to perform 2D convolution\n",
    "X_train = X_train.reshape(X_train.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "X_test = X_test.reshape(X_test.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_alexnet():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(128, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(192, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(192, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(128, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20400 samples, validate on 13600 samples\n",
      "Epoch 1/50\n",
      "20400/20400 [==============================] - 38s 2ms/step - loss: 3.0751 - acc: 0.0549 - val_loss: 2.9954 - val_acc: 0.0532\n",
      "Epoch 2/50\n",
      "20400/20400 [==============================] - 38s 2ms/step - loss: 2.9190 - acc: 0.0820 - val_loss: 2.6755 - val_acc: 0.1400\n",
      "Epoch 3/50\n",
      "20400/20400 [==============================] - 37s 2ms/step - loss: 2.5642 - acc: 0.1758 - val_loss: 1.9935 - val_acc: 0.3759\n",
      "Epoch 4/50\n",
      "20400/20400 [==============================] - 41s 2ms/step - loss: 1.9991 - acc: 0.3544 - val_loss: 1.4978 - val_acc: 0.5457\n",
      "Epoch 5/50\n",
      "20400/20400 [==============================] - 40s 2ms/step - loss: 1.5501 - acc: 0.5049 - val_loss: 1.2038 - val_acc: 0.6081\n",
      "Epoch 6/50\n",
      "20400/20400 [==============================] - 43s 2ms/step - loss: 1.2604 - acc: 0.6043 - val_loss: 0.9772 - val_acc: 0.6974\n",
      "Epoch 7/50\n",
      "20400/20400 [==============================] - 39s 2ms/step - loss: 1.0609 - acc: 0.6741 - val_loss: 0.8832 - val_acc: 0.7276\n",
      "Epoch 8/50\n",
      "20400/20400 [==============================] - 42s 2ms/step - loss: 0.9304 - acc: 0.7184 - val_loss: 0.7605 - val_acc: 0.7702\n",
      "Epoch 9/50\n",
      "20400/20400 [==============================] - 42s 2ms/step - loss: 0.7969 - acc: 0.7645 - val_loss: 0.7378 - val_acc: 0.7779\n",
      "Epoch 10/50\n",
      "20400/20400 [==============================] - 43s 2ms/step - loss: 0.7215 - acc: 0.7890 - val_loss: 0.7172 - val_acc: 0.7906\n",
      "Epoch 11/50\n",
      "20400/20400 [==============================] - 41s 2ms/step - loss: 0.6488 - acc: 0.8107 - val_loss: 0.7008 - val_acc: 0.7968\n",
      "Epoch 12/50\n",
      "20400/20400 [==============================] - 46s 2ms/step - loss: 0.5812 - acc: 0.8261 - val_loss: 0.7216 - val_acc: 0.7963\n",
      "Epoch 13/50\n",
      "20400/20400 [==============================] - 42s 2ms/step - loss: 0.5383 - acc: 0.8438 - val_loss: 0.6705 - val_acc: 0.8141\n",
      "Epoch 14/50\n",
      "20400/20400 [==============================] - 45s 2ms/step - loss: 0.4847 - acc: 0.8614 - val_loss: 0.6796 - val_acc: 0.8119\n",
      "Epoch 15/50\n",
      "20400/20400 [==============================] - 42s 2ms/step - loss: 0.4361 - acc: 0.8718 - val_loss: 0.7032 - val_acc: 0.8111\n",
      "Epoch 16/50\n",
      "20400/20400 [==============================] - 40s 2ms/step - loss: 0.4091 - acc: 0.8809 - val_loss: 0.6875 - val_acc: 0.8187\n",
      "Epoch 17/50\n",
      "20400/20400 [==============================] - 41s 2ms/step - loss: 0.3618 - acc: 0.8940 - val_loss: 0.6725 - val_acc: 0.8269\n",
      "Epoch 18/50\n",
      "20400/20400 [==============================] - 42s 2ms/step - loss: 0.3531 - acc: 0.8983 - val_loss: 0.7048 - val_acc: 0.8245\n",
      "Epoch 19/50\n",
      "20400/20400 [==============================] - 41s 2ms/step - loss: 0.3136 - acc: 0.9101 - val_loss: 0.7901 - val_acc: 0.8202\n",
      "Epoch 20/50\n",
      "20400/20400 [==============================] - 42s 2ms/step - loss: 0.2872 - acc: 0.9177 - val_loss: 0.7400 - val_acc: 0.8271\n",
      "Epoch 21/50\n",
      "20400/20400 [==============================] - 40s 2ms/step - loss: 0.2738 - acc: 0.9215 - val_loss: 0.7828 - val_acc: 0.8210\n",
      "Epoch 22/50\n",
      "20400/20400 [==============================] - 41s 2ms/step - loss: 0.2525 - acc: 0.9272 - val_loss: 0.8036 - val_acc: 0.8188\n",
      "Epoch 23/50\n",
      "20400/20400 [==============================] - 41s 2ms/step - loss: 0.2279 - acc: 0.9339 - val_loss: 0.7537 - val_acc: 0.8382\n",
      "Epoch 24/50\n",
      "20400/20400 [==============================] - 42s 2ms/step - loss: 0.2371 - acc: 0.9316 - val_loss: 0.7966 - val_acc: 0.8318\n",
      "Epoch 25/50\n",
      "20400/20400 [==============================] - 40s 2ms/step - loss: 0.2078 - acc: 0.9404 - val_loss: 0.8173 - val_acc: 0.8275\n",
      "Epoch 26/50\n",
      "20400/20400 [==============================] - 41s 2ms/step - loss: 0.2092 - acc: 0.9418 - val_loss: 0.7793 - val_acc: 0.8360\n",
      "Epoch 27/50\n",
      "20400/20400 [==============================] - 41s 2ms/step - loss: 0.1815 - acc: 0.9464 - val_loss: 0.8234 - val_acc: 0.8306\n",
      "Epoch 28/50\n",
      "20400/20400 [==============================] - 40s 2ms/step - loss: 0.1946 - acc: 0.9466 - val_loss: 0.8038 - val_acc: 0.8393\n",
      "Epoch 29/50\n",
      "20400/20400 [==============================] - 42s 2ms/step - loss: 0.1663 - acc: 0.9540 - val_loss: 0.8981 - val_acc: 0.8342\n",
      "Epoch 30/50\n",
      "20400/20400 [==============================] - 40s 2ms/step - loss: 0.1590 - acc: 0.9563 - val_loss: 0.9031 - val_acc: 0.8364\n",
      "Epoch 31/50\n",
      "20400/20400 [==============================] - 40s 2ms/step - loss: 0.1726 - acc: 0.9518 - val_loss: 0.8636 - val_acc: 0.8298\n",
      "Epoch 32/50\n",
      "20400/20400 [==============================] - 40s 2ms/step - loss: 0.1521 - acc: 0.9591 - val_loss: 0.8497 - val_acc: 0.8393\n",
      "Epoch 33/50\n",
      "20400/20400 [==============================] - 40s 2ms/step - loss: 0.1376 - acc: 0.9608 - val_loss: 0.8526 - val_acc: 0.8438\n",
      "Epoch 34/50\n",
      "20400/20400 [==============================] - 39s 2ms/step - loss: 0.1320 - acc: 0.9632 - val_loss: 0.9086 - val_acc: 0.8405\n",
      "Epoch 35/50\n",
      "20400/20400 [==============================] - 41s 2ms/step - loss: 0.1478 - acc: 0.9609 - val_loss: 0.8907 - val_acc: 0.8412\n",
      "Epoch 36/50\n",
      "20400/20400 [==============================] - 41s 2ms/step - loss: 0.1282 - acc: 0.9644 - val_loss: 0.8976 - val_acc: 0.8382\n",
      "Epoch 37/50\n",
      "20400/20400 [==============================] - 41s 2ms/step - loss: 0.1271 - acc: 0.9661 - val_loss: 0.9907 - val_acc: 0.8347\n",
      "Epoch 38/50\n",
      "20400/20400 [==============================] - 40s 2ms/step - loss: 0.1139 - acc: 0.9706 - val_loss: 1.0221 - val_acc: 0.8340\n",
      "Epoch 39/50\n",
      "20400/20400 [==============================] - 46s 2ms/step - loss: 0.1228 - acc: 0.9670 - val_loss: 1.0560 - val_acc: 0.8282\n",
      "Epoch 40/50\n",
      "20400/20400 [==============================] - 53s 3ms/step - loss: 0.1166 - acc: 0.9699 - val_loss: 0.9952 - val_acc: 0.8415\n",
      "Epoch 41/50\n",
      "20400/20400 [==============================] - 47s 2ms/step - loss: 0.1135 - acc: 0.9689 - val_loss: 1.0185 - val_acc: 0.8257\n",
      "Epoch 42/50\n",
      "20400/20400 [==============================] - 45s 2ms/step - loss: 0.1013 - acc: 0.9729 - val_loss: 1.2344 - val_acc: 0.8215\n",
      "Epoch 43/50\n",
      "20400/20400 [==============================] - 44s 2ms/step - loss: 0.1127 - acc: 0.9692 - val_loss: 1.0590 - val_acc: 0.8356\n",
      "Epoch 44/50\n",
      "20400/20400 [==============================] - 45s 2ms/step - loss: 0.1235 - acc: 0.9682 - val_loss: 1.0292 - val_acc: 0.8413\n",
      "Epoch 45/50\n",
      "20400/20400 [==============================] - 47s 2ms/step - loss: 0.1029 - acc: 0.9730 - val_loss: 1.0650 - val_acc: 0.8373\n",
      "Epoch 46/50\n",
      "20400/20400 [==============================] - 47s 2ms/step - loss: 0.0873 - acc: 0.9769 - val_loss: 1.1118 - val_acc: 0.8374\n",
      "Epoch 47/50\n",
      "20400/20400 [==============================] - 50s 2ms/step - loss: 0.1054 - acc: 0.9727 - val_loss: 1.0123 - val_acc: 0.8369\n",
      "Epoch 48/50\n",
      "20400/20400 [==============================] - 46s 2ms/step - loss: 0.1033 - acc: 0.9748 - val_loss: 1.0262 - val_acc: 0.8376\n",
      "Epoch 49/50\n",
      "20400/20400 [==============================] - 47s 2ms/step - loss: 0.0915 - acc: 0.9759 - val_loss: 1.0692 - val_acc: 0.8413\n",
      "Epoch 50/50\n",
      "20400/20400 [==============================] - 48s 2ms/step - loss: 0.0935 - acc: 0.9773 - val_loss: 1.2168 - val_acc: 0.8274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff13ab92fd0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_alexnet()\n",
    "model.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D,AveragePooling2D,ZeroPadding2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicts one sample\n",
    "def predict(filepath, model):\n",
    "    sample = wav2mfcc(filepath)\n",
    "    sample_reshaped = sample.reshape(1, feature_dim_1, feature_dim_2, channel)\n",
    "    return get_labels()[0][\n",
    "            np.argmax(model.predict(sample_reshaped))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(Conv2D(128, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(128, kernel_size=(2, 2), activation='relu'))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    #model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Predicts one sample\n",
    "def predict(filepath, model):\n",
    "    sample = wav2mfcc(filepath)\n",
    "    sample_reshaped = sample.reshape(1, feature_dim_1, feature_dim_2, channel)\n",
    "    return get_labels()[0][\n",
    "            np.argmax(model.predict(sample_reshaped))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model = model_alexnet()\n",
    "#model.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nine\n"
     ]
    }
   ],
   "source": [
    "print(predict('/home/daniel/datatest/nine/d8ee4734_nohash_0.wav', model=model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
